{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nabla GPU Tutorial: Training a Neural Network to Learn a Complex Sin Function\n",
    "\n",
    "In this tutorial, we'll walk through how to use Nabla with GPU acceleration to train a neural network to learn a complex sin function. We'll cover installation, device setup, and the training loop with jitting for GPU acceleration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ Nabla is ready! Running on Python 3.10\n"
     ]
    }
   ],
   "source": [
    "# Google Colab & Installation Setup\n",
    "import sys\n",
    "\n",
    "# Check if we're running in Google Colab\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"ðŸš€ Running in Google Colab!\")\n",
    "    print(\"ðŸ“¦ Installing modular and nabla-ml...\")\n",
    "    import subprocess\n",
    "\n",
    "    # Install Modular nightly first\n",
    "    subprocess.check_call(\n",
    "        [\n",
    "            sys.executable,\n",
    "            \"-m\",\n",
    "            \"pip\",\n",
    "            \"install\",\n",
    "            \"modular\",\n",
    "            \"--extra-index-url\",\n",
    "            \"https://download.pytorch.org/whl/cpu\",\n",
    "            \"--index-url\",\n",
    "            \"https://dl.modular.com/public/nightly/python/simple/\",\n",
    "        ]\n",
    "    )\n",
    "    # Then install nabla-ml\n",
    "    subprocess.check_call(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"nabla-ml\", \"--upgrade\"]\n",
    "    )\n",
    "    print(\"âœ… Installation complete!\")\n",
    "\n",
    "# Import nabla\n",
    "try:\n",
    "    import time\n",
    "\n",
    "    import numpy as np\n",
    "    from max import driver\n",
    "\n",
    "    import nabla as nb\n",
    "\n",
    "    print(\n",
    "        f\"ðŸŽ‰ Nabla is ready! Running on Python {sys.version_info.major}.{sys.version_info.minor}\"\n",
    "    )\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Error importing nabla: {e}\")\n",
    "    print(\"ðŸ’¡ Try restarting the runtime if you just installed nabla-ml\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Nabla and GPU Acceleration\n",
    "\n",
    "Nabla is a deep learning library that leverages the Modular MLIR compiler for high-performance computation. One of its key features is GPU acceleration, which is achieved through jitting (Just-In-Time compilation). This means that functions decorated with `@nb.jit` are compiled into optimized GPU code by the Modular compiler.\n",
    "\n",
    "### Why `to(device)`?\n",
    "\n",
    "In Nabla, tensors need to be explicitly moved to the desired device (CPU or GPU) using the `to(device)` method. This is because Nabla's GPU mode is only accessible within jitted functions. The device is determined at runtime, and tensors must be on the correct device for operations to execute efficiently.\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Jitting**: Functions decorated with `@nb.jit` are compiled and optimized for GPU execution.\n",
    "2. **Device Placement**: Tensors must be moved to the appropriate device using `to(device)`.\n",
    "3. **Training Loop**: The training loop involves creating datasets, computing gradients, and updating parameters using an optimizer.\n",
    "\n",
    "Let's dive into the implementation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device(type=gpu,id=0) device\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "BATCH_SIZE = 4\n",
    "LAYERS = [1, 64, 128, 256, 128, 64, 1]\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "PRINT_INTERVAL = 1\n",
    "SIN_PERIODS = 8\n",
    "\n",
    "device = driver.CPU() if driver.accelerator_count() == 0 else driver.Accelerator()\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_forward(x: nb.Array, params: list[nb.Array]) -> nb.Array:\n",
    "    \"\"\"MLP forward pass through all layers.\"\"\"\n",
    "    output = x\n",
    "    for i in range(0, len(params) - 1, 2):\n",
    "        w, b = params[i], params[i + 1]\n",
    "        output = nb.matmul(output, w) + b\n",
    "        # Apply ReLU to all layers except the last\n",
    "        if i < len(params) - 2:\n",
    "            output = nb.relu(output)\n",
    "    return output\n",
    "\n",
    "\n",
    "def mean_squared_error(predictions: nb.Array, targets: nb.Array) -> nb.Array:\n",
    "    \"\"\"Compute mean squared error loss.\"\"\"\n",
    "    diff = predictions - targets\n",
    "    squared_errors = diff * diff\n",
    "    batch_size = nb.array(predictions.shape[0], dtype=nb.DType.float32).to(device)\n",
    "    loss = nb.sum(squared_errors) / batch_size\n",
    "    return loss\n",
    "\n",
    "\n",
    "def mlp_forward_and_loss(inputs: list[nb.Array]) -> nb.Array:\n",
    "    \"\"\"Combined forward pass and loss computation for VJP with leaky ReLU.\"\"\"\n",
    "    x, targets, *params = inputs\n",
    "    predictions = mlp_forward(x, params)\n",
    "    loss = mean_squared_error(predictions, targets)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sin_dataset(batch_size: int = 256) -> tuple[nb.Array, nb.Array]:\n",
    "    \"\"\"Create the COMPLEX 8-period sin dataset.\"\"\"\n",
    "    x = nb.rand((batch_size, 1), lower=0.0, upper=1.0, dtype=nb.DType.float32).to(\n",
    "        device\n",
    "    )\n",
    "    targets = nb.sin(SIN_PERIODS * 2.0 * np.pi * x) / 2.0 + 0.5\n",
    "    return x, targets\n",
    "\n",
    "\n",
    "def initialize_for_complex_function(\n",
    "    layers: list[int], seed: int = 42\n",
    ") -> list[nb.Array]:\n",
    "    \"\"\"Initialize specifically for learning complex high-frequency functions.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    params = []\n",
    "\n",
    "    for i in range(len(layers) - 1):\n",
    "        fan_in, fan_out = layers[i], layers[i + 1]\n",
    "        w = nb.he_normal((fan_in, fan_out), seed=seed).to(device)\n",
    "        b = nb.zeros((fan_out,)).to(device)\n",
    "        params.append(w)\n",
    "        params.append(b)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adamw_step(\n",
    "    params: list[nb.Array],\n",
    "    gradients: list[nb.Array],\n",
    "    m_states: list[nb.Array],\n",
    "    v_states: list[nb.Array],\n",
    "    step: int,\n",
    "    learning_rate: float = 0.001,\n",
    "    beta1: float = 0.9,\n",
    "    beta2: float = 0.999,\n",
    "    eps: float = 1e-8,\n",
    "    weight_decay: float = 0.01,\n",
    ") -> tuple[list[nb.Array], list[nb.Array], list[nb.Array]]:\n",
    "    \"\"\"AdamW optimizer step with weight decay - OPTIMIZED to match JAX efficiency.\"\"\"\n",
    "    updated_params = []\n",
    "    updated_m = []\n",
    "    updated_v = []\n",
    "\n",
    "    for param, grad, m, v in zip(params, gradients, m_states, v_states, strict=False):\n",
    "        # Update moments\n",
    "        new_m = beta1 * m + (1.0 - beta1) * grad\n",
    "        new_v = beta2 * v + (1.0 - beta2) * (grad * grad)\n",
    "\n",
    "        # Bias correction\n",
    "        bias_correction1 = 1.0 - beta1**step\n",
    "        bias_correction2 = 1.0 - beta2**step\n",
    "\n",
    "        # Corrected moments\n",
    "        m_corrected = new_m / bias_correction1\n",
    "        v_corrected = new_v / bias_correction2\n",
    "\n",
    "        # Parameter update with weight decay\n",
    "        new_param = param - learning_rate * (\n",
    "            m_corrected / (v_corrected**0.5 + eps) + weight_decay * param\n",
    "        )\n",
    "\n",
    "        # Append updated values\n",
    "        updated_params.append(new_param)\n",
    "        updated_m.append(new_m)\n",
    "        updated_v.append(new_v)\n",
    "\n",
    "    return updated_params, updated_m, updated_v\n",
    "\n",
    "\n",
    "def init_adamw_state(params: list[nb.Array]) -> tuple[list[nb.Array], list[nb.Array]]:\n",
    "    \"\"\"Initialize AdamW state - optimized version.\"\"\"\n",
    "    m_states = []\n",
    "    v_states = []\n",
    "    for param in params:\n",
    "        # Use zeros_like for more efficient initialization\n",
    "        m_np = np.zeros_like(param.to_numpy())\n",
    "        v_np = np.zeros_like(param.to_numpy())\n",
    "        m_states.append(nb.Array.from_numpy(m_np).to(device))\n",
    "        v_states.append(nb.Array.from_numpy(v_np).to(device))\n",
    "    return m_states, v_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_schedule(\n",
    "    epoch: int,\n",
    "    initial_lr: float = 0.001,\n",
    "    decay_factor: float = 0.95,\n",
    "    decay_every: int = 1000,\n",
    ") -> float:\n",
    "    \"\"\"Learning rate schedule for complex function learning.\"\"\"\n",
    "    return initial_lr * (decay_factor ** (epoch // decay_every))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(show_graph=True)\n",
    "def train_step(\n",
    "    x: nb.Array,\n",
    "    targets: nb.Array,\n",
    "    params: list[nb.Array],\n",
    "    m_states: list[nb.Array],\n",
    "    v_states: list[nb.Array],\n",
    "    step: int,\n",
    "    learning_rate: float,\n",
    ") -> tuple[list[nb.Array], list[nb.Array], list[nb.Array], nb.Array]:\n",
    "    \"\"\"JIT-compiled training step combining gradient computation and optimizer update.\"\"\"\n",
    "\n",
    "    # Define loss function that takes separate arguments (JAX style)\n",
    "    def loss_fn(*inner_params):\n",
    "        predictions = mlp_forward(x, inner_params)\n",
    "        loss = mean_squared_error(predictions, targets)\n",
    "        return loss\n",
    "\n",
    "    loss_value, param_gradients = nb.value_and_grad(\n",
    "        loss_fn, argnums=list(range(len(params)))\n",
    "    )(*params)\n",
    "\n",
    "    # AdamW optimizer update\n",
    "    updated_params, updated_m, updated_v = adamw_step(\n",
    "        params, param_gradients, m_states, v_states, step, learning_rate\n",
    "    )\n",
    "\n",
    "    return updated_params, updated_m, updated_v, loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit\n",
    "def compute_predictions_and_loss(\n",
    "    x_test: nb.Array, targets_test: nb.Array, params: list[nb.Array]\n",
    ") -> tuple[nb.Array, nb.Array]:\n",
    "    \"\"\"JIT-compiled function to compute predictions and loss.\"\"\"\n",
    "    predictions_test = mlp_forward(x_test, params)\n",
    "    test_loss = mean_squared_error(predictions_test, targets_test)\n",
    "    return predictions_test, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Learning COMPLEX 8-Period Sin Function with Nabla JIT ===\n",
      "Architecture: [1, 64, 128, 256, 128, 64, 1]\n",
      "Initial learning rate: 0.001\n",
      "Sin periods: 8\n",
      "Batch size: 4\n",
      "Initial loss: 2.015263\n",
      "Initial predictions range: [-1.115, -0.850]\n",
      "Targets range: [0.008, 0.887]\n",
      "\n",
      "Starting training...\n",
      "mo.graph @nabla_graph(%arg0: !mo.tensor<[1, 64], f32, gpu:0>, %arg1: !mo.tensor<[], f32>, %arg2: !mo.tensor<[64], f32, gpu:0>, %arg3: !mo.tensor<[4, 1], f32, gpu:0>, %arg4: !mo.tensor<[64, 128], f32, gpu:0>, %arg5: !mo.tensor<[128], f32, gpu:0>, %arg6: !mo.tensor<[128, 256], f32, gpu:0>, %arg7: !mo.tensor<[256], f32, gpu:0>, %arg8: !mo.tensor<[256, 128], f32, gpu:0>, %arg9: !mo.tensor<[128], f32, gpu:0>, %arg10: !mo.tensor<[128, 64], f32, gpu:0>, %arg11: !mo.tensor<[64], f32, gpu:0>, %arg12: !mo.tensor<[64, 1], f32, gpu:0>, %arg13: !mo.tensor<[4, 1], f32, gpu:0>, %arg14: !mo.tensor<[1], f32, gpu:0>, %arg15: !mo.tensor<[1, 64], f32, gpu:0>, %arg16: !mo.tensor<[1, 64], f32, gpu:0>, %arg17: !mo.tensor<[64], f32, gpu:0>, %arg18: !mo.tensor<[64], f32, gpu:0>, %arg19: !mo.tensor<[64, 128], f32, gpu:0>, %arg20: !mo.tensor<[64, 128], f32, gpu:0>, %arg21: !mo.tensor<[128], f32, gpu:0>, %arg22: !mo.tensor<[128], f32, gpu:0>, %arg23: !mo.tensor<[128, 256], f32, gpu:0>, %arg24: !mo.tensor<[128, 256], f32, gpu:0>, %arg25: !mo.tensor<[256], f32, gpu:0>, %arg26: !mo.tensor<[256], f32, gpu:0>, %arg27: !mo.tensor<[256, 128], f32, gpu:0>, %arg28: !mo.tensor<[256, 128], f32, gpu:0>, %arg29: !mo.tensor<[128], f32, gpu:0>, %arg30: !mo.tensor<[128], f32, gpu:0>, %arg31: !mo.tensor<[128, 64], f32, gpu:0>, %arg32: !mo.tensor<[128, 64], f32, gpu:0>, %arg33: !mo.tensor<[64], f32, gpu:0>, %arg34: !mo.tensor<[64], f32, gpu:0>, %arg35: !mo.tensor<[64, 1], f32, gpu:0>, %arg36: !mo.tensor<[64, 1], f32, gpu:0>, %arg37: !mo.tensor<[1], f32, gpu:0>, %arg38: !mo.tensor<[1], f32, gpu:0>) -> (!mo.tensor<[1, 64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>, !mo.tensor<[256], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>, !mo.tensor<[1], f32, gpu:0>, !mo.tensor<[1, 64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>, !mo.tensor<[256], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>, !mo.tensor<[1], f32, gpu:0>, !mo.tensor<[1, 64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>, !mo.tensor<[256], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>, !mo.tensor<[1], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) attributes {_kernel_library_paths = [], argument_names = [\"input0\", \"input1\", \"input2\", \"input3\", \"input4\", \"input5\", \"input6\", \"input7\", \"input8\", \"input9\", \"input10\", \"input11\", \"input12\", \"input13\", \"input14\", \"input15\", \"input16\", \"input17\", \"input18\", \"input19\", \"input20\", \"input21\", \"input22\", \"input23\", \"input24\", \"input25\", \"input26\", \"input27\", \"input28\", \"input29\", \"input30\", \"input31\", \"input32\", \"input33\", \"input34\", \"input35\", \"input36\", \"input37\", \"input38\"], result_names = [\"output0\", \"output1\", \"output2\", \"output3\", \"output4\", \"output5\", \"output6\", \"output7\", \"output8\", \"output9\", \"output10\", \"output11\", \"output12\", \"output13\", \"output14\", \"output15\", \"output16\", \"output17\", \"output18\", \"output19\", \"output20\", \"output21\", \"output22\", \"output23\", \"output24\", \"output25\", \"output26\", \"output27\", \"output28\", \"output29\", \"output30\", \"output31\", \"output32\", \"output33\", \"output34\", \"output35\", \"output36\"]} {\n",
      "  %0 = mo.chain.create()\n",
      "  %1 = mo.constant {value = #M.dense_array<0.00999999977> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %2 = mo.constant {value = #M.dense_array<9.99999993E-9> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %3 = mo.constant {value = #M.dense_array<5.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %4 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %5 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %6 = mo.constant {value = #M.dense_array<0.000000e+00> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %7 = mo.constant {value = #M.dense_array<0.000000e+00> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %8 = mo.constant {value = #M.dense_array<0.000000e+00> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %9 = mo.constant {value = #M.dense_array<0.000000e+00> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %10 = mo.constant {value = #M.dense_array<0.000000e+00> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %11 = mo.constant {value = #M.dense_array<2.500000e-01, 2.500000e-01, 2.500000e-01, 2.500000e-01> : tensor<4x1xf32>} : !mo.tensor<[4, 1], f32, gpu:0>\n",
      "  %12 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %13 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %14 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %15 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %16 = mo.constant {value = #M.dense_array<1.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %17 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %18 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %19 = mo.constant {value = #M.dense_array<0.00999999977> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %20 = mo.constant {value = #M.dense_array<9.99999993E-9> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %21 = mo.constant {value = #M.dense_array<5.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %22 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %23 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %24 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %25 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %26 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %27 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %28 = mo.constant {value = #M.dense_array<1.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %29 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %30 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %31 = mo.constant {value = #M.dense_array<0.00999999977> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %32 = mo.constant {value = #M.dense_array<9.99999993E-9> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %33 = mo.constant {value = #M.dense_array<5.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %34 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %35 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %36 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %37 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %38 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %39 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %40 = mo.constant {value = #M.dense_array<1.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %41 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %42 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %43 = mo.constant {value = #M.dense_array<0.00999999977> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %44 = mo.constant {value = #M.dense_array<9.99999993E-9> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %45 = mo.constant {value = #M.dense_array<5.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %46 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %47 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %48 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %49 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %50 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %51 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %52 = mo.constant {value = #M.dense_array<1.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %53 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %54 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %55 = mo.constant {value = #M.dense_array<0.00999999977> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %56 = mo.constant {value = #M.dense_array<9.99999993E-9> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %57 = mo.constant {value = #M.dense_array<5.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %58 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %59 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %60 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %61 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %62 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %63 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %64 = mo.constant {value = #M.dense_array<1.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %65 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %66 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %67 = mo.constant {value = #M.dense_array<0.00999999977> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %68 = mo.constant {value = #M.dense_array<9.99999993E-9> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %69 = mo.constant {value = #M.dense_array<5.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %70 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %71 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %72 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %73 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %74 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %75 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %76 = mo.constant {value = #M.dense_array<1.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %77 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %78 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %79 = mo.constant {value = #M.dense_array<0.00999999977> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %80 = mo.constant {value = #M.dense_array<9.99999993E-9> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %81 = mo.constant {value = #M.dense_array<5.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %82 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %83 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %84 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %85 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %86 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %87 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %88 = mo.constant {value = #M.dense_array<1.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %89 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %90 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %91 = mo.constant {value = #M.dense_array<0.00999999977> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %92 = mo.constant {value = #M.dense_array<9.99999993E-9> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %93 = mo.constant {value = #M.dense_array<5.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %94 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %95 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %96 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %97 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %98 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %99 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %100 = mo.constant {value = #M.dense_array<1.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %101 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %102 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %103 = mo.constant {value = #M.dense_array<0.00999999977> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %104 = mo.constant {value = #M.dense_array<9.99999993E-9> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %105 = mo.constant {value = #M.dense_array<5.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %106 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %107 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %108 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %109 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %110 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %111 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %112 = mo.constant {value = #M.dense_array<1.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %113 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %114 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %115 = mo.constant {value = #M.dense_array<0.00999999977> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %116 = mo.constant {value = #M.dense_array<9.99999993E-9> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %117 = mo.constant {value = #M.dense_array<5.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %118 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %119 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %120 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %121 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %122 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %123 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %124 = mo.constant {value = #M.dense_array<1.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %125 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %126 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %127 = mo.constant {value = #M.dense_array<0.00999999977> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %128 = mo.constant {value = #M.dense_array<9.99999993E-9> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %129 = mo.constant {value = #M.dense_array<5.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %130 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %131 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %132 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %133 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %134 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %135 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %136 = mo.constant {value = #M.dense_array<1.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %137 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %138 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %139 = mo.constant {value = #M.dense_array<0.00999999977> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %140 = mo.constant {value = #M.dense_array<9.99999993E-9> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %141 = mo.constant {value = #M.dense_array<5.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %142 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %143 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %144 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %145 = mo.constant {value = #M.dense_array<9.990000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %146 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %147 = mo.constant {value = #M.dense_array<1.000000e+00> : tensor<f32>} : !mo.tensor<[], f32>\n",
      "  %148 = mo.constant {value = #M.dense_array<1.000000e-01> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %149 = mo.constant {value = #M.dense_array<0.899999976> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %150 = mo.constant {value = #M.dense_array<1.000000e-03> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %151 = mo.constant {value = #M.dense_array<4.000000e+00> : tensor<f32>} : !mo.tensor<[], f32, gpu:0>\n",
      "  %152 = rmo.mul(%1, %arg0) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[1, 64], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %153 = rmo.pow(%4, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %154 = rmo.sub(%5, %153) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %155 = rmo.mo.transfer %154 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %156 = rmo.reshape(%155) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %157 = rmo.reshape(%156) {newShape = #mosh<ape[1, 1]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1, 1], f32, gpu:0>\n",
      "  %158 = rmo.broadcast_to(%157) {newShape = #mosh<ape[1, 64]> : !mosh.ape} : (!mo.tensor<[1, 1], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %159 = rmo.reshape(%arg2) {newShape = #mosh<ape[1, 64]> : !mosh.ape} : (!mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %160 = rmo.broadcast_to(%159) {newShape = #mosh<ape[4, 64]> : !mosh.ape} : (!mo.tensor<[1, 64], f32, gpu:0>) -> !mo.tensor<[4, 64], f32, gpu:0>\n",
      "  %161 = rmo.matmul(%arg3, %arg0) : (!mo.tensor<[4, 1], f32, gpu:0>, !mo.tensor<[1, 64], f32, gpu:0>) -> !mo.tensor<[4, 64], f32, gpu:0>\n",
      "  %162 = rmo.add(%161, %160) : (!mo.tensor<[4, 64], f32, gpu:0>, !mo.tensor<[4, 64], f32, gpu:0>) -> !mo.tensor<[4, 64], f32, gpu:0>\n",
      "  %163 = rmo.greater_equal(%162, %6) : (!mo.tensor<[4, 64], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[4, 64], bool, gpu:0>\n",
      "  %164 = mo.cast(%163) : (!mo.tensor<[4, 64], bool, gpu:0>) -> !mo.tensor<[4, 64], f32, gpu:0>\n",
      "  %165 = mo.constant {value = #M.dense_array<1, 0> : tensor<2xsi64>} : !mo.tensor<[2], si64>\n",
      "  %166 = rmo.mo.transpose(%arg4, %165) : (!mo.tensor<[64, 128], f32, gpu:0>, !mo.tensor<[2], si64>) -> !mo.tensor<[128, 64], f32, gpu:0>\n",
      "  %167 = rmo.reshape(%arg5) {newShape = #mosh<ape[1, 128]> : !mosh.ape} : (!mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[1, 128], f32, gpu:0>\n",
      "  %168 = rmo.broadcast_to(%167) {newShape = #mosh<ape[4, 128]> : !mosh.ape} : (!mo.tensor<[1, 128], f32, gpu:0>) -> !mo.tensor<[4, 128], f32, gpu:0>\n",
      "  %169 = rmo.mo.relu(%162) : (!mo.tensor<[4, 64], f32, gpu:0>) -> !mo.tensor<[4, 64], f32, gpu:0>\n",
      "  %170 = rmo.matmul(%169, %arg4) : (!mo.tensor<[4, 64], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>) -> !mo.tensor<[4, 128], f32, gpu:0>\n",
      "  %171 = rmo.add(%170, %168) : (!mo.tensor<[4, 128], f32, gpu:0>, !mo.tensor<[4, 128], f32, gpu:0>) -> !mo.tensor<[4, 128], f32, gpu:0>\n",
      "  %172 = rmo.greater_equal(%171, %7) : (!mo.tensor<[4, 128], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[4, 128], bool, gpu:0>\n",
      "  %173 = mo.cast(%172) : (!mo.tensor<[4, 128], bool, gpu:0>) -> !mo.tensor<[4, 128], f32, gpu:0>\n",
      "  %174 = mo.constant {value = #M.dense_array<1, 0> : tensor<2xsi64>} : !mo.tensor<[2], si64>\n",
      "  %175 = rmo.mo.transpose(%arg6, %174) : (!mo.tensor<[128, 256], f32, gpu:0>, !mo.tensor<[2], si64>) -> !mo.tensor<[256, 128], f32, gpu:0>\n",
      "  %176 = rmo.reshape(%arg7) {newShape = #mosh<ape[1, 256]> : !mosh.ape} : (!mo.tensor<[256], f32, gpu:0>) -> !mo.tensor<[1, 256], f32, gpu:0>\n",
      "  %177 = rmo.broadcast_to(%176) {newShape = #mosh<ape[4, 256]> : !mosh.ape} : (!mo.tensor<[1, 256], f32, gpu:0>) -> !mo.tensor<[4, 256], f32, gpu:0>\n",
      "  %178 = rmo.mo.relu(%171) : (!mo.tensor<[4, 128], f32, gpu:0>) -> !mo.tensor<[4, 128], f32, gpu:0>\n",
      "  %179 = rmo.matmul(%178, %arg6) : (!mo.tensor<[4, 128], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>) -> !mo.tensor<[4, 256], f32, gpu:0>\n",
      "  %180 = rmo.add(%179, %177) : (!mo.tensor<[4, 256], f32, gpu:0>, !mo.tensor<[4, 256], f32, gpu:0>) -> !mo.tensor<[4, 256], f32, gpu:0>\n",
      "  %181 = rmo.greater_equal(%180, %8) : (!mo.tensor<[4, 256], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[4, 256], bool, gpu:0>\n",
      "  %182 = mo.cast(%181) : (!mo.tensor<[4, 256], bool, gpu:0>) -> !mo.tensor<[4, 256], f32, gpu:0>\n",
      "  %183 = mo.constant {value = #M.dense_array<1, 0> : tensor<2xsi64>} : !mo.tensor<[2], si64>\n",
      "  %184 = rmo.mo.transpose(%arg8, %183) : (!mo.tensor<[256, 128], f32, gpu:0>, !mo.tensor<[2], si64>) -> !mo.tensor<[128, 256], f32, gpu:0>\n",
      "  %185 = rmo.reshape(%arg9) {newShape = #mosh<ape[1, 128]> : !mosh.ape} : (!mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[1, 128], f32, gpu:0>\n",
      "  %186 = rmo.broadcast_to(%185) {newShape = #mosh<ape[4, 128]> : !mosh.ape} : (!mo.tensor<[1, 128], f32, gpu:0>) -> !mo.tensor<[4, 128], f32, gpu:0>\n",
      "  %187 = rmo.mo.relu(%180) : (!mo.tensor<[4, 256], f32, gpu:0>) -> !mo.tensor<[4, 256], f32, gpu:0>\n",
      "  %188 = rmo.matmul(%187, %arg8) : (!mo.tensor<[4, 256], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>) -> !mo.tensor<[4, 128], f32, gpu:0>\n",
      "  %189 = rmo.add(%188, %186) : (!mo.tensor<[4, 128], f32, gpu:0>, !mo.tensor<[4, 128], f32, gpu:0>) -> !mo.tensor<[4, 128], f32, gpu:0>\n",
      "  %190 = rmo.greater_equal(%189, %9) : (!mo.tensor<[4, 128], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[4, 128], bool, gpu:0>\n",
      "  %191 = mo.cast(%190) : (!mo.tensor<[4, 128], bool, gpu:0>) -> !mo.tensor<[4, 128], f32, gpu:0>\n",
      "  %192 = mo.constant {value = #M.dense_array<1, 0> : tensor<2xsi64>} : !mo.tensor<[2], si64>\n",
      "  %193 = rmo.mo.transpose(%arg10, %192) : (!mo.tensor<[128, 64], f32, gpu:0>, !mo.tensor<[2], si64>) -> !mo.tensor<[64, 128], f32, gpu:0>\n",
      "  %194 = rmo.reshape(%arg11) {newShape = #mosh<ape[1, 64]> : !mosh.ape} : (!mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %195 = rmo.broadcast_to(%194) {newShape = #mosh<ape[4, 64]> : !mosh.ape} : (!mo.tensor<[1, 64], f32, gpu:0>) -> !mo.tensor<[4, 64], f32, gpu:0>\n",
      "  %196 = rmo.mo.relu(%189) : (!mo.tensor<[4, 128], f32, gpu:0>) -> !mo.tensor<[4, 128], f32, gpu:0>\n",
      "  %197 = rmo.matmul(%196, %arg10) : (!mo.tensor<[4, 128], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>) -> !mo.tensor<[4, 64], f32, gpu:0>\n",
      "  %198 = rmo.add(%197, %195) : (!mo.tensor<[4, 64], f32, gpu:0>, !mo.tensor<[4, 64], f32, gpu:0>) -> !mo.tensor<[4, 64], f32, gpu:0>\n",
      "  %199 = rmo.greater_equal(%198, %10) : (!mo.tensor<[4, 64], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[4, 64], bool, gpu:0>\n",
      "  %200 = mo.cast(%199) : (!mo.tensor<[4, 64], bool, gpu:0>) -> !mo.tensor<[4, 64], f32, gpu:0>\n",
      "  %201 = mo.constant {value = #M.dense_array<1, 0> : tensor<2xsi64>} : !mo.tensor<[2], si64>\n",
      "  %202 = rmo.mo.transpose(%arg12, %201) : (!mo.tensor<[64, 1], f32, gpu:0>, !mo.tensor<[2], si64>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %203 = rmo.reshape(%arg14) {newShape = #mosh<ape[1, 1]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1, 1], f32, gpu:0>\n",
      "  %204 = rmo.broadcast_to(%203) {newShape = #mosh<ape[4, 1]> : !mosh.ape} : (!mo.tensor<[1, 1], f32, gpu:0>) -> !mo.tensor<[4, 1], f32, gpu:0>\n",
      "  %205 = rmo.mo.relu(%198) : (!mo.tensor<[4, 64], f32, gpu:0>) -> !mo.tensor<[4, 64], f32, gpu:0>\n",
      "  %206 = rmo.matmul(%205, %arg12) : (!mo.tensor<[4, 64], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>) -> !mo.tensor<[4, 1], f32, gpu:0>\n",
      "  %207 = rmo.add(%206, %204) : (!mo.tensor<[4, 1], f32, gpu:0>, !mo.tensor<[4, 1], f32, gpu:0>) -> !mo.tensor<[4, 1], f32, gpu:0>\n",
      "  %208 = rmo.sub(%207, %arg13) : (!mo.tensor<[4, 1], f32, gpu:0>, !mo.tensor<[4, 1], f32, gpu:0>) -> !mo.tensor<[4, 1], f32, gpu:0>\n",
      "  %209 = rmo.mul(%11, %208) : (!mo.tensor<[4, 1], f32, gpu:0>, !mo.tensor<[4, 1], f32, gpu:0>) -> !mo.tensor<[4, 1], f32, gpu:0>\n",
      "  %210 = rmo.mul(%11, %208) : (!mo.tensor<[4, 1], f32, gpu:0>, !mo.tensor<[4, 1], f32, gpu:0>) -> !mo.tensor<[4, 1], f32, gpu:0>\n",
      "  %211 = rmo.add(%210, %209) : (!mo.tensor<[4, 1], f32, gpu:0>, !mo.tensor<[4, 1], f32, gpu:0>) -> !mo.tensor<[4, 1], f32, gpu:0>\n",
      "  %212 = rmo.matmul(%211, %202) : (!mo.tensor<[4, 1], f32, gpu:0>, !mo.tensor<[1, 64], f32, gpu:0>) -> !mo.tensor<[4, 64], f32, gpu:0>\n",
      "  %213 = rmo.mul(%212, %200) : (!mo.tensor<[4, 64], f32, gpu:0>, !mo.tensor<[4, 64], f32, gpu:0>) -> !mo.tensor<[4, 64], f32, gpu:0>\n",
      "  %214 = rmo.matmul(%213, %193) : (!mo.tensor<[4, 64], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>) -> !mo.tensor<[4, 128], f32, gpu:0>\n",
      "  %215 = rmo.mul(%214, %191) : (!mo.tensor<[4, 128], f32, gpu:0>, !mo.tensor<[4, 128], f32, gpu:0>) -> !mo.tensor<[4, 128], f32, gpu:0>\n",
      "  %216 = rmo.matmul(%215, %184) : (!mo.tensor<[4, 128], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>) -> !mo.tensor<[4, 256], f32, gpu:0>\n",
      "  %217 = rmo.mul(%216, %182) : (!mo.tensor<[4, 256], f32, gpu:0>, !mo.tensor<[4, 256], f32, gpu:0>) -> !mo.tensor<[4, 256], f32, gpu:0>\n",
      "  %218 = rmo.matmul(%217, %175) : (!mo.tensor<[4, 256], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>) -> !mo.tensor<[4, 128], f32, gpu:0>\n",
      "  %219 = rmo.mul(%218, %173) : (!mo.tensor<[4, 128], f32, gpu:0>, !mo.tensor<[4, 128], f32, gpu:0>) -> !mo.tensor<[4, 128], f32, gpu:0>\n",
      "  %220 = rmo.matmul(%219, %166) : (!mo.tensor<[4, 128], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>) -> !mo.tensor<[4, 64], f32, gpu:0>\n",
      "  %221 = rmo.mul(%220, %164) : (!mo.tensor<[4, 64], f32, gpu:0>, !mo.tensor<[4, 64], f32, gpu:0>) -> !mo.tensor<[4, 64], f32, gpu:0>\n",
      "  %222 = mo.constant {value = #M.dense_array<1, 0> : tensor<2xsi64>} : !mo.tensor<[2], si64>\n",
      "  %223 = rmo.mo.transpose(%arg3, %222) : (!mo.tensor<[4, 1], f32, gpu:0>, !mo.tensor<[2], si64>) -> !mo.tensor<[1, 4], f32, gpu:0>\n",
      "  %224 = rmo.matmul(%223, %221) : (!mo.tensor<[1, 4], f32, gpu:0>, !mo.tensor<[4, 64], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %225 = rmo.mul(%224, %224) : (!mo.tensor<[1, 64], f32, gpu:0>, !mo.tensor<[1, 64], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %226 = rmo.mul(%12, %225) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[1, 64], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %227 = rmo.mul(%13, %arg15) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[1, 64], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %228 = rmo.add(%227, %226) : (!mo.tensor<[1, 64], f32, gpu:0>, !mo.tensor<[1, 64], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %229 = rmo.div(%228, %158) : (!mo.tensor<[1, 64], f32, gpu:0>, !mo.tensor<[1, 64], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %230 = rmo.pow(%229, %3) : (!mo.tensor<[1, 64], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %231 = rmo.add(%230, %2) : (!mo.tensor<[1, 64], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %232 = rmo.pow(%14, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %233 = rmo.sub(%15, %232) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %234 = rmo.mo.transfer %233 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %235 = rmo.reshape(%234) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %236 = rmo.reshape(%235) {newShape = #mosh<ape[1, 1]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1, 1], f32, gpu:0>\n",
      "  %237 = rmo.broadcast_to(%236) {newShape = #mosh<ape[1, 64]> : !mosh.ape} : (!mo.tensor<[1, 1], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %238 = rmo.mul(%16, %224) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[1, 64], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %239 = rmo.mul(%17, %arg16) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[1, 64], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %240 = rmo.add(%239, %238) : (!mo.tensor<[1, 64], f32, gpu:0>, !mo.tensor<[1, 64], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %241 = rmo.div(%240, %237) : (!mo.tensor<[1, 64], f32, gpu:0>, !mo.tensor<[1, 64], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %242 = rmo.div(%241, %231) : (!mo.tensor<[1, 64], f32, gpu:0>, !mo.tensor<[1, 64], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %243 = rmo.add(%242, %152) : (!mo.tensor<[1, 64], f32, gpu:0>, !mo.tensor<[1, 64], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %244 = rmo.mul(%18, %243) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[1, 64], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %245 = rmo.sub(%arg0, %244) : (!mo.tensor<[1, 64], f32, gpu:0>, !mo.tensor<[1, 64], f32, gpu:0>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %246 = rmo.mul(%19, %arg2) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %247 = rmo.pow(%22, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %248 = rmo.sub(%23, %247) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %249 = rmo.mo.transfer %248 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %250 = rmo.reshape(%249) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %251 = rmo.broadcast_to(%250) {newShape = #mosh<ape[64]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %252 = mo.constant {value = #M.dense_array<0> : tensor<si64>} : !mo.tensor<[], si64>\n",
      "  %253 = rmo.mo.reduce.add(%221, %252) : (!mo.tensor<[4, 64], f32, gpu:0>, !mo.tensor<[], si64>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %254 = rmo.reshape(%253) {newShape = #mosh<ape[64]> : !mosh.ape} : (!mo.tensor<[1, 64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %255 = rmo.mul(%254, %254) : (!mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %256 = rmo.mul(%24, %255) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %257 = rmo.mul(%25, %arg17) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %258 = rmo.add(%257, %256) : (!mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %259 = rmo.div(%258, %251) : (!mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %260 = rmo.pow(%259, %21) : (!mo.tensor<[64], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %261 = rmo.add(%260, %20) : (!mo.tensor<[64], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %262 = rmo.pow(%26, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %263 = rmo.sub(%27, %262) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %264 = rmo.mo.transfer %263 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %265 = rmo.reshape(%264) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %266 = rmo.broadcast_to(%265) {newShape = #mosh<ape[64]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %267 = rmo.mul(%28, %254) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %268 = rmo.mul(%29, %arg18) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %269 = rmo.add(%268, %267) : (!mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %270 = rmo.div(%269, %266) : (!mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %271 = rmo.div(%270, %261) : (!mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %272 = rmo.add(%271, %246) : (!mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %273 = rmo.mul(%30, %272) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %274 = rmo.sub(%arg2, %273) : (!mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %275 = rmo.mul(%31, %arg4) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>) -> !mo.tensor<[64, 128], f32, gpu:0>\n",
      "  %276 = rmo.pow(%34, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %277 = rmo.sub(%35, %276) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %278 = rmo.mo.transfer %277 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %279 = rmo.reshape(%278) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %280 = rmo.reshape(%279) {newShape = #mosh<ape[1, 1]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1, 1], f32, gpu:0>\n",
      "  %281 = rmo.broadcast_to(%280) {newShape = #mosh<ape[64, 128]> : !mosh.ape} : (!mo.tensor<[1, 1], f32, gpu:0>) -> !mo.tensor<[64, 128], f32, gpu:0>\n",
      "  %282 = mo.constant {value = #M.dense_array<1, 0> : tensor<2xsi64>} : !mo.tensor<[2], si64>\n",
      "  %283 = rmo.mo.transpose(%169, %282) : (!mo.tensor<[4, 64], f32, gpu:0>, !mo.tensor<[2], si64>) -> !mo.tensor<[64, 4], f32, gpu:0>\n",
      "  %284 = rmo.matmul(%283, %219) : (!mo.tensor<[64, 4], f32, gpu:0>, !mo.tensor<[4, 128], f32, gpu:0>) -> !mo.tensor<[64, 128], f32, gpu:0>\n",
      "  %285 = rmo.mul(%284, %284) : (!mo.tensor<[64, 128], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>) -> !mo.tensor<[64, 128], f32, gpu:0>\n",
      "  %286 = rmo.mul(%36, %285) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>) -> !mo.tensor<[64, 128], f32, gpu:0>\n",
      "  %287 = rmo.mul(%37, %arg19) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>) -> !mo.tensor<[64, 128], f32, gpu:0>\n",
      "  %288 = rmo.add(%287, %286) : (!mo.tensor<[64, 128], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>) -> !mo.tensor<[64, 128], f32, gpu:0>\n",
      "  %289 = rmo.div(%288, %281) : (!mo.tensor<[64, 128], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>) -> !mo.tensor<[64, 128], f32, gpu:0>\n",
      "  %290 = rmo.pow(%289, %33) : (!mo.tensor<[64, 128], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[64, 128], f32, gpu:0>\n",
      "  %291 = rmo.add(%290, %32) : (!mo.tensor<[64, 128], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[64, 128], f32, gpu:0>\n",
      "  %292 = rmo.pow(%38, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %293 = rmo.sub(%39, %292) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %294 = rmo.mo.transfer %293 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %295 = rmo.reshape(%294) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %296 = rmo.reshape(%295) {newShape = #mosh<ape[1, 1]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1, 1], f32, gpu:0>\n",
      "  %297 = rmo.broadcast_to(%296) {newShape = #mosh<ape[64, 128]> : !mosh.ape} : (!mo.tensor<[1, 1], f32, gpu:0>) -> !mo.tensor<[64, 128], f32, gpu:0>\n",
      "  %298 = rmo.mul(%40, %284) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>) -> !mo.tensor<[64, 128], f32, gpu:0>\n",
      "  %299 = rmo.mul(%41, %arg20) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>) -> !mo.tensor<[64, 128], f32, gpu:0>\n",
      "  %300 = rmo.add(%299, %298) : (!mo.tensor<[64, 128], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>) -> !mo.tensor<[64, 128], f32, gpu:0>\n",
      "  %301 = rmo.div(%300, %297) : (!mo.tensor<[64, 128], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>) -> !mo.tensor<[64, 128], f32, gpu:0>\n",
      "  %302 = rmo.div(%301, %291) : (!mo.tensor<[64, 128], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>) -> !mo.tensor<[64, 128], f32, gpu:0>\n",
      "  %303 = rmo.add(%302, %275) : (!mo.tensor<[64, 128], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>) -> !mo.tensor<[64, 128], f32, gpu:0>\n",
      "  %304 = rmo.mul(%42, %303) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>) -> !mo.tensor<[64, 128], f32, gpu:0>\n",
      "  %305 = rmo.sub(%arg4, %304) : (!mo.tensor<[64, 128], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>) -> !mo.tensor<[64, 128], f32, gpu:0>\n",
      "  %306 = rmo.mul(%43, %arg5) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %307 = rmo.pow(%46, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %308 = rmo.sub(%47, %307) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %309 = rmo.mo.transfer %308 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %310 = rmo.reshape(%309) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %311 = rmo.broadcast_to(%310) {newShape = #mosh<ape[128]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %312 = mo.constant {value = #M.dense_array<0> : tensor<si64>} : !mo.tensor<[], si64>\n",
      "  %313 = rmo.mo.reduce.add(%219, %312) : (!mo.tensor<[4, 128], f32, gpu:0>, !mo.tensor<[], si64>) -> !mo.tensor<[1, 128], f32, gpu:0>\n",
      "  %314 = rmo.reshape(%313) {newShape = #mosh<ape[128]> : !mosh.ape} : (!mo.tensor<[1, 128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %315 = rmo.mul(%314, %314) : (!mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %316 = rmo.mul(%48, %315) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %317 = rmo.mul(%49, %arg21) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %318 = rmo.add(%317, %316) : (!mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %319 = rmo.div(%318, %311) : (!mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %320 = rmo.pow(%319, %45) : (!mo.tensor<[128], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %321 = rmo.add(%320, %44) : (!mo.tensor<[128], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %322 = rmo.pow(%50, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %323 = rmo.sub(%51, %322) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %324 = rmo.mo.transfer %323 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %325 = rmo.reshape(%324) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %326 = rmo.broadcast_to(%325) {newShape = #mosh<ape[128]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %327 = rmo.mul(%52, %314) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %328 = rmo.mul(%53, %arg22) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %329 = rmo.add(%328, %327) : (!mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %330 = rmo.div(%329, %326) : (!mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %331 = rmo.div(%330, %321) : (!mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %332 = rmo.add(%331, %306) : (!mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %333 = rmo.mul(%54, %332) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %334 = rmo.sub(%arg5, %333) : (!mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %335 = rmo.mul(%55, %arg6) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>) -> !mo.tensor<[128, 256], f32, gpu:0>\n",
      "  %336 = rmo.pow(%58, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %337 = rmo.sub(%59, %336) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %338 = rmo.mo.transfer %337 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %339 = rmo.reshape(%338) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %340 = rmo.reshape(%339) {newShape = #mosh<ape[1, 1]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1, 1], f32, gpu:0>\n",
      "  %341 = rmo.broadcast_to(%340) {newShape = #mosh<ape[128, 256]> : !mosh.ape} : (!mo.tensor<[1, 1], f32, gpu:0>) -> !mo.tensor<[128, 256], f32, gpu:0>\n",
      "  %342 = mo.constant {value = #M.dense_array<1, 0> : tensor<2xsi64>} : !mo.tensor<[2], si64>\n",
      "  %343 = rmo.mo.transpose(%178, %342) : (!mo.tensor<[4, 128], f32, gpu:0>, !mo.tensor<[2], si64>) -> !mo.tensor<[128, 4], f32, gpu:0>\n",
      "  %344 = rmo.matmul(%343, %217) : (!mo.tensor<[128, 4], f32, gpu:0>, !mo.tensor<[4, 256], f32, gpu:0>) -> !mo.tensor<[128, 256], f32, gpu:0>\n",
      "  %345 = rmo.mul(%344, %344) : (!mo.tensor<[128, 256], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>) -> !mo.tensor<[128, 256], f32, gpu:0>\n",
      "  %346 = rmo.mul(%60, %345) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>) -> !mo.tensor<[128, 256], f32, gpu:0>\n",
      "  %347 = rmo.mul(%61, %arg23) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>) -> !mo.tensor<[128, 256], f32, gpu:0>\n",
      "  %348 = rmo.add(%347, %346) : (!mo.tensor<[128, 256], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>) -> !mo.tensor<[128, 256], f32, gpu:0>\n",
      "  %349 = rmo.div(%348, %341) : (!mo.tensor<[128, 256], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>) -> !mo.tensor<[128, 256], f32, gpu:0>\n",
      "  %350 = rmo.pow(%349, %57) : (!mo.tensor<[128, 256], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[128, 256], f32, gpu:0>\n",
      "  %351 = rmo.add(%350, %56) : (!mo.tensor<[128, 256], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[128, 256], f32, gpu:0>\n",
      "  %352 = rmo.pow(%62, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %353 = rmo.sub(%63, %352) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %354 = rmo.mo.transfer %353 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %355 = rmo.reshape(%354) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %356 = rmo.reshape(%355) {newShape = #mosh<ape[1, 1]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1, 1], f32, gpu:0>\n",
      "  %357 = rmo.broadcast_to(%356) {newShape = #mosh<ape[128, 256]> : !mosh.ape} : (!mo.tensor<[1, 1], f32, gpu:0>) -> !mo.tensor<[128, 256], f32, gpu:0>\n",
      "  %358 = rmo.mul(%64, %344) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>) -> !mo.tensor<[128, 256], f32, gpu:0>\n",
      "  %359 = rmo.mul(%65, %arg24) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>) -> !mo.tensor<[128, 256], f32, gpu:0>\n",
      "  %360 = rmo.add(%359, %358) : (!mo.tensor<[128, 256], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>) -> !mo.tensor<[128, 256], f32, gpu:0>\n",
      "  %361 = rmo.div(%360, %357) : (!mo.tensor<[128, 256], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>) -> !mo.tensor<[128, 256], f32, gpu:0>\n",
      "  %362 = rmo.div(%361, %351) : (!mo.tensor<[128, 256], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>) -> !mo.tensor<[128, 256], f32, gpu:0>\n",
      "  %363 = rmo.add(%362, %335) : (!mo.tensor<[128, 256], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>) -> !mo.tensor<[128, 256], f32, gpu:0>\n",
      "  %364 = rmo.mul(%66, %363) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>) -> !mo.tensor<[128, 256], f32, gpu:0>\n",
      "  %365 = rmo.sub(%arg6, %364) : (!mo.tensor<[128, 256], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>) -> !mo.tensor<[128, 256], f32, gpu:0>\n",
      "  %366 = rmo.mul(%67, %arg7) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[256], f32, gpu:0>) -> !mo.tensor<[256], f32, gpu:0>\n",
      "  %367 = rmo.pow(%70, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %368 = rmo.sub(%71, %367) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %369 = rmo.mo.transfer %368 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %370 = rmo.reshape(%369) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %371 = rmo.broadcast_to(%370) {newShape = #mosh<ape[256]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[256], f32, gpu:0>\n",
      "  %372 = mo.constant {value = #M.dense_array<0> : tensor<si64>} : !mo.tensor<[], si64>\n",
      "  %373 = rmo.mo.reduce.add(%217, %372) : (!mo.tensor<[4, 256], f32, gpu:0>, !mo.tensor<[], si64>) -> !mo.tensor<[1, 256], f32, gpu:0>\n",
      "  %374 = rmo.reshape(%373) {newShape = #mosh<ape[256]> : !mosh.ape} : (!mo.tensor<[1, 256], f32, gpu:0>) -> !mo.tensor<[256], f32, gpu:0>\n",
      "  %375 = rmo.mul(%374, %374) : (!mo.tensor<[256], f32, gpu:0>, !mo.tensor<[256], f32, gpu:0>) -> !mo.tensor<[256], f32, gpu:0>\n",
      "  %376 = rmo.mul(%72, %375) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[256], f32, gpu:0>) -> !mo.tensor<[256], f32, gpu:0>\n",
      "  %377 = rmo.mul(%73, %arg25) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[256], f32, gpu:0>) -> !mo.tensor<[256], f32, gpu:0>\n",
      "  %378 = rmo.add(%377, %376) : (!mo.tensor<[256], f32, gpu:0>, !mo.tensor<[256], f32, gpu:0>) -> !mo.tensor<[256], f32, gpu:0>\n",
      "  %379 = rmo.div(%378, %371) : (!mo.tensor<[256], f32, gpu:0>, !mo.tensor<[256], f32, gpu:0>) -> !mo.tensor<[256], f32, gpu:0>\n",
      "  %380 = rmo.pow(%379, %69) : (!mo.tensor<[256], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[256], f32, gpu:0>\n",
      "  %381 = rmo.add(%380, %68) : (!mo.tensor<[256], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[256], f32, gpu:0>\n",
      "  %382 = rmo.pow(%74, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %383 = rmo.sub(%75, %382) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %384 = rmo.mo.transfer %383 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %385 = rmo.reshape(%384) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %386 = rmo.broadcast_to(%385) {newShape = #mosh<ape[256]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[256], f32, gpu:0>\n",
      "  %387 = rmo.mul(%76, %374) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[256], f32, gpu:0>) -> !mo.tensor<[256], f32, gpu:0>\n",
      "  %388 = rmo.mul(%77, %arg26) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[256], f32, gpu:0>) -> !mo.tensor<[256], f32, gpu:0>\n",
      "  %389 = rmo.add(%388, %387) : (!mo.tensor<[256], f32, gpu:0>, !mo.tensor<[256], f32, gpu:0>) -> !mo.tensor<[256], f32, gpu:0>\n",
      "  %390 = rmo.div(%389, %386) : (!mo.tensor<[256], f32, gpu:0>, !mo.tensor<[256], f32, gpu:0>) -> !mo.tensor<[256], f32, gpu:0>\n",
      "  %391 = rmo.div(%390, %381) : (!mo.tensor<[256], f32, gpu:0>, !mo.tensor<[256], f32, gpu:0>) -> !mo.tensor<[256], f32, gpu:0>\n",
      "  %392 = rmo.add(%391, %366) : (!mo.tensor<[256], f32, gpu:0>, !mo.tensor<[256], f32, gpu:0>) -> !mo.tensor<[256], f32, gpu:0>\n",
      "  %393 = rmo.mul(%78, %392) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[256], f32, gpu:0>) -> !mo.tensor<[256], f32, gpu:0>\n",
      "  %394 = rmo.sub(%arg7, %393) : (!mo.tensor<[256], f32, gpu:0>, !mo.tensor<[256], f32, gpu:0>) -> !mo.tensor<[256], f32, gpu:0>\n",
      "  %395 = rmo.mul(%79, %arg8) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>) -> !mo.tensor<[256, 128], f32, gpu:0>\n",
      "  %396 = rmo.pow(%82, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %397 = rmo.sub(%83, %396) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %398 = rmo.mo.transfer %397 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %399 = rmo.reshape(%398) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %400 = rmo.reshape(%399) {newShape = #mosh<ape[1, 1]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1, 1], f32, gpu:0>\n",
      "  %401 = rmo.broadcast_to(%400) {newShape = #mosh<ape[256, 128]> : !mosh.ape} : (!mo.tensor<[1, 1], f32, gpu:0>) -> !mo.tensor<[256, 128], f32, gpu:0>\n",
      "  %402 = mo.constant {value = #M.dense_array<1, 0> : tensor<2xsi64>} : !mo.tensor<[2], si64>\n",
      "  %403 = rmo.mo.transpose(%187, %402) : (!mo.tensor<[4, 256], f32, gpu:0>, !mo.tensor<[2], si64>) -> !mo.tensor<[256, 4], f32, gpu:0>\n",
      "  %404 = rmo.matmul(%403, %215) : (!mo.tensor<[256, 4], f32, gpu:0>, !mo.tensor<[4, 128], f32, gpu:0>) -> !mo.tensor<[256, 128], f32, gpu:0>\n",
      "  %405 = rmo.mul(%404, %404) : (!mo.tensor<[256, 128], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>) -> !mo.tensor<[256, 128], f32, gpu:0>\n",
      "  %406 = rmo.mul(%84, %405) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>) -> !mo.tensor<[256, 128], f32, gpu:0>\n",
      "  %407 = rmo.mul(%85, %arg27) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>) -> !mo.tensor<[256, 128], f32, gpu:0>\n",
      "  %408 = rmo.add(%407, %406) : (!mo.tensor<[256, 128], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>) -> !mo.tensor<[256, 128], f32, gpu:0>\n",
      "  %409 = rmo.div(%408, %401) : (!mo.tensor<[256, 128], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>) -> !mo.tensor<[256, 128], f32, gpu:0>\n",
      "  %410 = rmo.pow(%409, %81) : (!mo.tensor<[256, 128], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[256, 128], f32, gpu:0>\n",
      "  %411 = rmo.add(%410, %80) : (!mo.tensor<[256, 128], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[256, 128], f32, gpu:0>\n",
      "  %412 = rmo.pow(%86, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %413 = rmo.sub(%87, %412) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %414 = rmo.mo.transfer %413 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %415 = rmo.reshape(%414) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %416 = rmo.reshape(%415) {newShape = #mosh<ape[1, 1]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1, 1], f32, gpu:0>\n",
      "  %417 = rmo.broadcast_to(%416) {newShape = #mosh<ape[256, 128]> : !mosh.ape} : (!mo.tensor<[1, 1], f32, gpu:0>) -> !mo.tensor<[256, 128], f32, gpu:0>\n",
      "  %418 = rmo.mul(%88, %404) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>) -> !mo.tensor<[256, 128], f32, gpu:0>\n",
      "  %419 = rmo.mul(%89, %arg28) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>) -> !mo.tensor<[256, 128], f32, gpu:0>\n",
      "  %420 = rmo.add(%419, %418) : (!mo.tensor<[256, 128], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>) -> !mo.tensor<[256, 128], f32, gpu:0>\n",
      "  %421 = rmo.div(%420, %417) : (!mo.tensor<[256, 128], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>) -> !mo.tensor<[256, 128], f32, gpu:0>\n",
      "  %422 = rmo.div(%421, %411) : (!mo.tensor<[256, 128], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>) -> !mo.tensor<[256, 128], f32, gpu:0>\n",
      "  %423 = rmo.add(%422, %395) : (!mo.tensor<[256, 128], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>) -> !mo.tensor<[256, 128], f32, gpu:0>\n",
      "  %424 = rmo.mul(%90, %423) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>) -> !mo.tensor<[256, 128], f32, gpu:0>\n",
      "  %425 = rmo.sub(%arg8, %424) : (!mo.tensor<[256, 128], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>) -> !mo.tensor<[256, 128], f32, gpu:0>\n",
      "  %426 = rmo.mul(%91, %arg9) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %427 = rmo.pow(%94, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %428 = rmo.sub(%95, %427) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %429 = rmo.mo.transfer %428 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %430 = rmo.reshape(%429) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %431 = rmo.broadcast_to(%430) {newShape = #mosh<ape[128]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %432 = mo.constant {value = #M.dense_array<0> : tensor<si64>} : !mo.tensor<[], si64>\n",
      "  %433 = rmo.mo.reduce.add(%215, %432) : (!mo.tensor<[4, 128], f32, gpu:0>, !mo.tensor<[], si64>) -> !mo.tensor<[1, 128], f32, gpu:0>\n",
      "  %434 = rmo.reshape(%433) {newShape = #mosh<ape[128]> : !mosh.ape} : (!mo.tensor<[1, 128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %435 = rmo.mul(%434, %434) : (!mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %436 = rmo.mul(%96, %435) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %437 = rmo.mul(%97, %arg29) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %438 = rmo.add(%437, %436) : (!mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %439 = rmo.div(%438, %431) : (!mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %440 = rmo.pow(%439, %93) : (!mo.tensor<[128], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %441 = rmo.add(%440, %92) : (!mo.tensor<[128], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %442 = rmo.pow(%98, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %443 = rmo.sub(%99, %442) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %444 = rmo.mo.transfer %443 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %445 = rmo.reshape(%444) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %446 = rmo.broadcast_to(%445) {newShape = #mosh<ape[128]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %447 = rmo.mul(%100, %434) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %448 = rmo.mul(%101, %arg30) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %449 = rmo.add(%448, %447) : (!mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %450 = rmo.div(%449, %446) : (!mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %451 = rmo.div(%450, %441) : (!mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %452 = rmo.add(%451, %426) : (!mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %453 = rmo.mul(%102, %452) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %454 = rmo.sub(%arg9, %453) : (!mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>) -> !mo.tensor<[128], f32, gpu:0>\n",
      "  %455 = rmo.mul(%103, %arg10) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>) -> !mo.tensor<[128, 64], f32, gpu:0>\n",
      "  %456 = rmo.pow(%106, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %457 = rmo.sub(%107, %456) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %458 = rmo.mo.transfer %457 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %459 = rmo.reshape(%458) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %460 = rmo.reshape(%459) {newShape = #mosh<ape[1, 1]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1, 1], f32, gpu:0>\n",
      "  %461 = rmo.broadcast_to(%460) {newShape = #mosh<ape[128, 64]> : !mosh.ape} : (!mo.tensor<[1, 1], f32, gpu:0>) -> !mo.tensor<[128, 64], f32, gpu:0>\n",
      "  %462 = mo.constant {value = #M.dense_array<1, 0> : tensor<2xsi64>} : !mo.tensor<[2], si64>\n",
      "  %463 = rmo.mo.transpose(%196, %462) : (!mo.tensor<[4, 128], f32, gpu:0>, !mo.tensor<[2], si64>) -> !mo.tensor<[128, 4], f32, gpu:0>\n",
      "  %464 = rmo.matmul(%463, %213) : (!mo.tensor<[128, 4], f32, gpu:0>, !mo.tensor<[4, 64], f32, gpu:0>) -> !mo.tensor<[128, 64], f32, gpu:0>\n",
      "  %465 = rmo.mul(%464, %464) : (!mo.tensor<[128, 64], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>) -> !mo.tensor<[128, 64], f32, gpu:0>\n",
      "  %466 = rmo.mul(%108, %465) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>) -> !mo.tensor<[128, 64], f32, gpu:0>\n",
      "  %467 = rmo.mul(%109, %arg31) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>) -> !mo.tensor<[128, 64], f32, gpu:0>\n",
      "  %468 = rmo.add(%467, %466) : (!mo.tensor<[128, 64], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>) -> !mo.tensor<[128, 64], f32, gpu:0>\n",
      "  %469 = rmo.div(%468, %461) : (!mo.tensor<[128, 64], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>) -> !mo.tensor<[128, 64], f32, gpu:0>\n",
      "  %470 = rmo.pow(%469, %105) : (!mo.tensor<[128, 64], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[128, 64], f32, gpu:0>\n",
      "  %471 = rmo.add(%470, %104) : (!mo.tensor<[128, 64], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[128, 64], f32, gpu:0>\n",
      "  %472 = rmo.pow(%110, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %473 = rmo.sub(%111, %472) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %474 = rmo.mo.transfer %473 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %475 = rmo.reshape(%474) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %476 = rmo.reshape(%475) {newShape = #mosh<ape[1, 1]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1, 1], f32, gpu:0>\n",
      "  %477 = rmo.broadcast_to(%476) {newShape = #mosh<ape[128, 64]> : !mosh.ape} : (!mo.tensor<[1, 1], f32, gpu:0>) -> !mo.tensor<[128, 64], f32, gpu:0>\n",
      "  %478 = rmo.mul(%112, %464) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>) -> !mo.tensor<[128, 64], f32, gpu:0>\n",
      "  %479 = rmo.mul(%113, %arg32) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>) -> !mo.tensor<[128, 64], f32, gpu:0>\n",
      "  %480 = rmo.add(%479, %478) : (!mo.tensor<[128, 64], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>) -> !mo.tensor<[128, 64], f32, gpu:0>\n",
      "  %481 = rmo.div(%480, %477) : (!mo.tensor<[128, 64], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>) -> !mo.tensor<[128, 64], f32, gpu:0>\n",
      "  %482 = rmo.div(%481, %471) : (!mo.tensor<[128, 64], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>) -> !mo.tensor<[128, 64], f32, gpu:0>\n",
      "  %483 = rmo.add(%482, %455) : (!mo.tensor<[128, 64], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>) -> !mo.tensor<[128, 64], f32, gpu:0>\n",
      "  %484 = rmo.mul(%114, %483) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>) -> !mo.tensor<[128, 64], f32, gpu:0>\n",
      "  %485 = rmo.sub(%arg10, %484) : (!mo.tensor<[128, 64], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>) -> !mo.tensor<[128, 64], f32, gpu:0>\n",
      "  %486 = rmo.mul(%115, %arg11) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %487 = rmo.pow(%118, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %488 = rmo.sub(%119, %487) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %489 = rmo.mo.transfer %488 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %490 = rmo.reshape(%489) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %491 = rmo.broadcast_to(%490) {newShape = #mosh<ape[64]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %492 = mo.constant {value = #M.dense_array<0> : tensor<si64>} : !mo.tensor<[], si64>\n",
      "  %493 = rmo.mo.reduce.add(%213, %492) : (!mo.tensor<[4, 64], f32, gpu:0>, !mo.tensor<[], si64>) -> !mo.tensor<[1, 64], f32, gpu:0>\n",
      "  %494 = rmo.reshape(%493) {newShape = #mosh<ape[64]> : !mosh.ape} : (!mo.tensor<[1, 64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %495 = rmo.mul(%494, %494) : (!mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %496 = rmo.mul(%120, %495) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %497 = rmo.mul(%121, %arg33) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %498 = rmo.add(%497, %496) : (!mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %499 = rmo.div(%498, %491) : (!mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %500 = rmo.pow(%499, %117) : (!mo.tensor<[64], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %501 = rmo.add(%500, %116) : (!mo.tensor<[64], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %502 = rmo.pow(%122, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %503 = rmo.sub(%123, %502) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %504 = rmo.mo.transfer %503 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %505 = rmo.reshape(%504) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %506 = rmo.broadcast_to(%505) {newShape = #mosh<ape[64]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %507 = rmo.mul(%124, %494) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %508 = rmo.mul(%125, %arg34) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %509 = rmo.add(%508, %507) : (!mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %510 = rmo.div(%509, %506) : (!mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %511 = rmo.div(%510, %501) : (!mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %512 = rmo.add(%511, %486) : (!mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %513 = rmo.mul(%126, %512) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %514 = rmo.sub(%arg11, %513) : (!mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>) -> !mo.tensor<[64], f32, gpu:0>\n",
      "  %515 = rmo.mul(%127, %arg12) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>) -> !mo.tensor<[64, 1], f32, gpu:0>\n",
      "  %516 = rmo.pow(%130, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %517 = rmo.sub(%131, %516) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %518 = rmo.mo.transfer %517 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %519 = rmo.reshape(%518) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %520 = rmo.reshape(%519) {newShape = #mosh<ape[1, 1]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1, 1], f32, gpu:0>\n",
      "  %521 = rmo.broadcast_to(%520) {newShape = #mosh<ape[64, 1]> : !mosh.ape} : (!mo.tensor<[1, 1], f32, gpu:0>) -> !mo.tensor<[64, 1], f32, gpu:0>\n",
      "  %522 = mo.constant {value = #M.dense_array<1, 0> : tensor<2xsi64>} : !mo.tensor<[2], si64>\n",
      "  %523 = rmo.mo.transpose(%205, %522) : (!mo.tensor<[4, 64], f32, gpu:0>, !mo.tensor<[2], si64>) -> !mo.tensor<[64, 4], f32, gpu:0>\n",
      "  %524 = rmo.matmul(%523, %211) : (!mo.tensor<[64, 4], f32, gpu:0>, !mo.tensor<[4, 1], f32, gpu:0>) -> !mo.tensor<[64, 1], f32, gpu:0>\n",
      "  %525 = rmo.mul(%524, %524) : (!mo.tensor<[64, 1], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>) -> !mo.tensor<[64, 1], f32, gpu:0>\n",
      "  %526 = rmo.mul(%132, %525) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>) -> !mo.tensor<[64, 1], f32, gpu:0>\n",
      "  %527 = rmo.mul(%133, %arg35) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>) -> !mo.tensor<[64, 1], f32, gpu:0>\n",
      "  %528 = rmo.add(%527, %526) : (!mo.tensor<[64, 1], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>) -> !mo.tensor<[64, 1], f32, gpu:0>\n",
      "  %529 = rmo.div(%528, %521) : (!mo.tensor<[64, 1], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>) -> !mo.tensor<[64, 1], f32, gpu:0>\n",
      "  %530 = rmo.pow(%529, %129) : (!mo.tensor<[64, 1], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[64, 1], f32, gpu:0>\n",
      "  %531 = rmo.add(%530, %128) : (!mo.tensor<[64, 1], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[64, 1], f32, gpu:0>\n",
      "  %532 = rmo.pow(%134, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %533 = rmo.sub(%135, %532) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %534 = rmo.mo.transfer %533 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %535 = rmo.reshape(%534) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %536 = rmo.reshape(%535) {newShape = #mosh<ape[1, 1]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1, 1], f32, gpu:0>\n",
      "  %537 = rmo.broadcast_to(%536) {newShape = #mosh<ape[64, 1]> : !mosh.ape} : (!mo.tensor<[1, 1], f32, gpu:0>) -> !mo.tensor<[64, 1], f32, gpu:0>\n",
      "  %538 = rmo.mul(%136, %524) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>) -> !mo.tensor<[64, 1], f32, gpu:0>\n",
      "  %539 = rmo.mul(%137, %arg36) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>) -> !mo.tensor<[64, 1], f32, gpu:0>\n",
      "  %540 = rmo.add(%539, %538) : (!mo.tensor<[64, 1], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>) -> !mo.tensor<[64, 1], f32, gpu:0>\n",
      "  %541 = rmo.div(%540, %537) : (!mo.tensor<[64, 1], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>) -> !mo.tensor<[64, 1], f32, gpu:0>\n",
      "  %542 = rmo.div(%541, %531) : (!mo.tensor<[64, 1], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>) -> !mo.tensor<[64, 1], f32, gpu:0>\n",
      "  %543 = rmo.add(%542, %515) : (!mo.tensor<[64, 1], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>) -> !mo.tensor<[64, 1], f32, gpu:0>\n",
      "  %544 = rmo.mul(%138, %543) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>) -> !mo.tensor<[64, 1], f32, gpu:0>\n",
      "  %545 = rmo.sub(%arg12, %544) : (!mo.tensor<[64, 1], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>) -> !mo.tensor<[64, 1], f32, gpu:0>\n",
      "  %546 = rmo.mul(%139, %arg14) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %547 = rmo.pow(%142, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %548 = rmo.sub(%143, %547) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %549 = rmo.mo.transfer %548 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %550 = rmo.reshape(%549) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %551 = mo.constant {value = #M.dense_array<0> : tensor<si64>} : !mo.tensor<[], si64>\n",
      "  %552 = rmo.mo.reduce.add(%211, %551) : (!mo.tensor<[4, 1], f32, gpu:0>, !mo.tensor<[], si64>) -> !mo.tensor<[1, 1], f32, gpu:0>\n",
      "  %553 = rmo.reshape(%552) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[1, 1], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %554 = rmo.mul(%553, %553) : (!mo.tensor<[1], f32, gpu:0>, !mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %555 = rmo.mul(%144, %554) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %556 = rmo.mul(%145, %arg37) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %557 = rmo.add(%556, %555) : (!mo.tensor<[1], f32, gpu:0>, !mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %558 = rmo.div(%557, %550) : (!mo.tensor<[1], f32, gpu:0>, !mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %559 = rmo.pow(%558, %141) : (!mo.tensor<[1], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %560 = rmo.add(%559, %140) : (!mo.tensor<[1], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %561 = rmo.pow(%146, %arg1) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %562 = rmo.sub(%147, %561) : (!mo.tensor<[], f32>, !mo.tensor<[], f32>) -> !mo.tensor<[], f32>\n",
      "  %563 = rmo.mo.transfer %562 : !mo.tensor<[], f32> to <\"gpu\", 0>\n",
      "  %564 = rmo.reshape(%563) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %565 = rmo.mul(%148, %553) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %566 = rmo.mul(%149, %arg38) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %567 = rmo.add(%566, %565) : (!mo.tensor<[1], f32, gpu:0>, !mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %568 = rmo.div(%567, %564) : (!mo.tensor<[1], f32, gpu:0>, !mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %569 = rmo.div(%568, %560) : (!mo.tensor<[1], f32, gpu:0>, !mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %570 = rmo.add(%569, %546) : (!mo.tensor<[1], f32, gpu:0>, !mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %571 = rmo.mul(%150, %570) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %572 = rmo.sub(%arg14, %571) : (!mo.tensor<[1], f32, gpu:0>, !mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %573 = rmo.mul(%208, %208) : (!mo.tensor<[4, 1], f32, gpu:0>, !mo.tensor<[4, 1], f32, gpu:0>) -> !mo.tensor<[4, 1], f32, gpu:0>\n",
      "  %574 = mo.constant {value = #M.dense_array<0> : tensor<si64>} : !mo.tensor<[], si64>\n",
      "  %575 = rmo.mo.reduce.add(%573, %574) : (!mo.tensor<[4, 1], f32, gpu:0>, !mo.tensor<[], si64>) -> !mo.tensor<[1, 1], f32, gpu:0>\n",
      "  %576 = mo.constant {value = #M.dense_array<1> : tensor<si64>} : !mo.tensor<[], si64>\n",
      "  %577 = rmo.mo.reduce.add(%575, %576) : (!mo.tensor<[1, 1], f32, gpu:0>, !mo.tensor<[], si64>) -> !mo.tensor<[1, 1], f32, gpu:0>\n",
      "  %578 = rmo.reshape(%577) {newShape = #mosh<ape[1]> : !mosh.ape} : (!mo.tensor<[1, 1], f32, gpu:0>) -> !mo.tensor<[1], f32, gpu:0>\n",
      "  %579 = rmo.reshape(%578) {newShape = #mosh<ape[]> : !mosh.ape} : (!mo.tensor<[1], f32, gpu:0>) -> !mo.tensor<[], f32, gpu:0>\n",
      "  %580 = rmo.div(%579, %151) : (!mo.tensor<[], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>) -> !mo.tensor<[], f32, gpu:0>\n",
      "  mo.output %245, %274, %305, %334, %365, %394, %425, %454, %485, %514, %545, %572, %240, %269, %300, %329, %360, %389, %420, %449, %480, %509, %540, %567, %228, %258, %288, %318, %348, %378, %408, %438, %468, %498, %528, %557, %580 : !mo.tensor<[1, 64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>, !mo.tensor<[256], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>, !mo.tensor<[1], f32, gpu:0>, !mo.tensor<[1, 64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>, !mo.tensor<[256], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>, !mo.tensor<[1], f32, gpu:0>, !mo.tensor<[1, 64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64, 128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128, 256], f32, gpu:0>, !mo.tensor<[256], f32, gpu:0>, !mo.tensor<[256, 128], f32, gpu:0>, !mo.tensor<[128], f32, gpu:0>, !mo.tensor<[128, 64], f32, gpu:0>, !mo.tensor<[64], f32, gpu:0>, !mo.tensor<[64, 1], f32, gpu:0>, !mo.tensor<[1], f32, gpu:0>, !mo.tensor<[], f32, gpu:0>\n",
      "} {counter = 1036 : i64}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def test_nabla_complex_sin():\n",
    "    \"\"\"Test Nabla implementation with JIT for complex sin learning.\"\"\"\n",
    "    print(\"=== Learning COMPLEX 8-Period Sin Function with Nabla JIT ===\")\n",
    "    print(f\"Architecture: {LAYERS}\")\n",
    "    print(f\"Initial learning rate: {LEARNING_RATE}\")\n",
    "    print(f\"Sin periods: {SIN_PERIODS}\")\n",
    "    print(f\"Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "    # Initialize for complex function learning\n",
    "    params = initialize_for_complex_function(LAYERS)\n",
    "    m_states, v_states = init_adamw_state(params)\n",
    "\n",
    "    # Initial analysis\n",
    "    x_init, targets_init = create_sin_dataset(BATCH_SIZE)\n",
    "    predictions_init = mlp_forward(x_init, params)\n",
    "    initial_loss = mean_squared_error(predictions_init, targets_init)\n",
    "\n",
    "    pred_init_np = predictions_init.to_numpy()\n",
    "    target_init_np = targets_init.to_numpy()\n",
    "\n",
    "    print(f\"Initial loss: {initial_loss.to_numpy().item():.6f}\")\n",
    "    print(\n",
    "        f\"Initial predictions range: [{pred_init_np.min():.3f}, {pred_init_np.max():.3f}]\"\n",
    "    )\n",
    "    print(f\"Targets range: [{target_init_np.min():.3f}, {target_init_np.max():.3f}]\")\n",
    "\n",
    "    print(\"\\nStarting training...\")\n",
    "\n",
    "    # Training loop\n",
    "    avg_loss = 0.0\n",
    "    avg_time = 0.0\n",
    "    avg_data_time = 0.0\n",
    "    avg_vjp_time = 0.0\n",
    "    avg_adamw_time = 0.0\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # Learning rate schedule\n",
    "        current_lr = learning_rate_schedule(epoch, LEARNING_RATE)\n",
    "\n",
    "        # Create fresh batch\n",
    "        data_start = time.time()\n",
    "        x, targets = create_sin_dataset(BATCH_SIZE)\n",
    "        data_time = time.time() - data_start\n",
    "\n",
    "        # Training step using JIT-compiled function\n",
    "        vjp_start = time.time()\n",
    "\n",
    "        # Use JIT-compiled training step (combines gradient computation and optimizer update)\n",
    "        updated_params, updated_m, updated_v, loss_values = train_step(\n",
    "            x, targets, params, m_states, v_states, epoch, current_lr\n",
    "        )\n",
    "\n",
    "        vjp_time = time.time() - vjp_start\n",
    "\n",
    "        # Update return values (no separate AdamW step needed)\n",
    "        params, m_states, v_states = updated_params, updated_m, updated_v\n",
    "        adamw_time = 0.0  # Already included in the JIT step\n",
    "\n",
    "        # Loss extraction and conversion\n",
    "        loss_value = loss_values.to_numpy().item()\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        avg_loss += loss_value\n",
    "        avg_time += epoch_time\n",
    "        avg_data_time += data_time\n",
    "        avg_vjp_time += vjp_time\n",
    "        avg_adamw_time += adamw_time\n",
    "\n",
    "        if epoch % PRINT_INTERVAL == 0:\n",
    "            print(f\"\\n{'=' * 60}\")\n",
    "            print(\n",
    "                f\"Epoch {epoch:3d} | Loss: {avg_loss / PRINT_INTERVAL:.6f} | Time: {avg_time / PRINT_INTERVAL:.4f}s\"\n",
    "            )\n",
    "            print(f\"{'=' * 60}\")\n",
    "            print(\n",
    "                f\"  â”œâ”€ Data Gen:   {avg_data_time / PRINT_INTERVAL:.4f}s ({avg_data_time / avg_time * 100:.1f}%)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"  â””â”€ JIT Step:   {avg_vjp_time / PRINT_INTERVAL:.4f}s ({avg_vjp_time / avg_time * 100:.1f}%)\"\n",
    "            )\n",
    "\n",
    "            avg_loss = 0.0\n",
    "            avg_time = 0.0\n",
    "            avg_data_time = 0.0\n",
    "            avg_vjp_time = 0.0\n",
    "            avg_adamw_time = 0.0\n",
    "\n",
    "    print(\"\\nNabla JIT training completed!\")\n",
    "\n",
    "    # Final evaluation\n",
    "    print(\"\\n=== Final Evaluation ===\")\n",
    "    x_test_np = np.linspace(0, 1, 1000).reshape(-1, 1).astype(np.float32)\n",
    "    targets_test_np = (\n",
    "        np.sin(SIN_PERIODS * 2.0 * np.pi * x_test_np) / 2.0 + 0.5\n",
    "    ).astype(np.float32)\n",
    "\n",
    "    x_test = nb.Array.from_numpy(x_test_np).to(device)\n",
    "    targets_test = nb.Array.from_numpy(targets_test_np).to(device)\n",
    "\n",
    "    # Use JIT-compiled function for evaluation\n",
    "    predictions_test, test_loss = compute_predictions_and_loss(\n",
    "        x_test, targets_test, params\n",
    "    )\n",
    "\n",
    "    pred_final_np = predictions_test.to_numpy()\n",
    "\n",
    "    final_test_loss = test_loss.to_numpy().item()\n",
    "\n",
    "    print(f\"Final test loss: {final_test_loss:.6f}\")\n",
    "    print(\n",
    "        f\"Final predictions range: [{pred_final_np.min():.3f}, {pred_final_np.max():.3f}]\"\n",
    "    )\n",
    "    print(f\"Target range: [{targets_test_np.min():.3f}, {targets_test_np.max():.3f}]\")\n",
    "\n",
    "    # Calculate correlation\n",
    "    correlation = np.corrcoef(pred_final_np.flatten(), targets_test_np.flatten())[0, 1]\n",
    "    print(f\"Prediction-target correlation: {correlation:.4f}\")\n",
    "\n",
    "    return final_test_loss, correlation\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    final_loss, correlation = test_nabla_complex_sin()\n",
    "    print(\"\\n=== Nabla JIT Summary ===\")\n",
    "    print(f\"Final test loss: {final_loss:.6f}\")\n",
    "    print(f\"Correlation with true function: {correlation:.4f}\")\n",
    "\n",
    "    if correlation > 0.95:\n",
    "        print(\"SUCCESS: Nabla JIT learned the complex function very well! ðŸŽ‰\")\n",
    "    elif correlation > 0.8:\n",
    "        print(\"GOOD: Nabla JIT learned the general shape well! ðŸ‘\")\n",
    "    elif correlation > 0.5:\n",
    "        print(\"PARTIAL: Some learning but needs improvement ðŸ¤”\")\n",
    "    else:\n",
    "        print(\"POOR: Nabla JIT failed to learn the complex function ðŸ˜ž\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we covered:\n",
    "\n",
    "1. **Installation**: Setting up Nabla with GPU support in Google Colab.\n",
    "2. **Device Setup**: Understanding and using `to(device)` for GPU acceleration.\n",
    "3. **Training Loop**: Implementing a neural network to learn a complex sin function with Nabla's jitting for GPU acceleration.\n",
    "\n",
    "By following this tutorial, you should now have a good understanding of how to use Nabla for GPU-accelerated deep learning tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

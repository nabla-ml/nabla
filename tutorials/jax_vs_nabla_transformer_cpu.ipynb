{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JAX vs. Nabla: Training a Transformer (CPU)\n",
    "\n",
    "This notebook provides a detailed, from-scratch implementation of a Transformer model for a sequence-reversal task. The goal is to compare the APIs and programming models of two deep learning frameworks: **JAX** and **Nabla**.\n",
    "\n",
    "Each core component of the Transformer is implemented for both frameworks in the same code cell, allowing for a direct comparison of their syntax and approach. The implementations are kept as architecturally similar as possible to highlight the differences in the libraries themselves.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand the fundamental building blocks of the Transformer architecture.\n",
    "- Compare the functional, JIT-centric approaches of JAX and Nabla.\n",
    "- See how a complete sequence-to-sequence model is built and trained in both frameworks.\n",
    "\n",
    "At the end of the notebook, you will find two separate code cells that run the complete training loops, one for JAX and one for Nabla, followed by visualization of the training loss curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Configuration\n",
    "\n",
    "First, we import the necessary libraries and define the configuration parameters for our model and training task. These parameters are identical for both the JAX and Nabla implementations to ensure a fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation and imports\n",
    "import sys\n",
    "from typing import Any\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "try:\n",
    "    import time\n",
    "\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from jax import value_and_grad\n",
    "\n",
    "    import nabla as nb\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "\n",
    "    # Install required packages\n",
    "    subprocess.run(\n",
    "        [\n",
    "            sys.executable,\n",
    "            \"-m\",\n",
    "            \"pip\",\n",
    "            \"install\",\n",
    "            \"jax\",\n",
    "            \"jaxlib\",\n",
    "            \"matplotlib\",\n",
    "            \"numpy\",\n",
    "            \"nabla-ml\",\n",
    "        ],\n",
    "        check=True,\n",
    "    )\n",
    "\n",
    "    # Re-import after installation\n",
    "    import time\n",
    "\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from jax import value_and_grad\n",
    "\n",
    "    import nabla as nb\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION (Shared for both JAX and Nabla)\n",
    "# ============================================================================\n",
    "\n",
    "# Task Configuration\n",
    "VOCAB_SIZE = 20  # Total vocabulary size (0=PAD, 1=START, 2=END, 3-19=content)\n",
    "SOURCE_SEQ_LEN = 9  # Length of input sequences to reverse\n",
    "TARGET_SEQ_LEN = SOURCE_SEQ_LEN + 2  # +1 for END token, +1 for START token in decoder\n",
    "MAX_SEQ_LEN = TARGET_SEQ_LEN\n",
    "\n",
    "# Model Architecture\n",
    "NUM_LAYERS = 2  # Number of encoder and decoder layers\n",
    "D_MODEL = 64  # Model dimension (embedding size)\n",
    "NUM_HEADS = 4  # Number of attention heads (must divide D_MODEL)\n",
    "D_FF = 128  # Feed-forward network hidden dimension\n",
    "\n",
    "# Training Configuration\n",
    "BATCH_SIZE = 64  # Number of sequences per training batch\n",
    "LEARNING_RATE = 0.0005  # AdamW learning rate\n",
    "NUM_EPOCHS = 500  # Total training epochs\n",
    "PRINT_INTERVAL = 10  # Print progress every N epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Positional Encoding\n",
    "\n",
    "Since Transformers do not have inherent knowledge of sequence order (unlike RNNs), we inject positional information using sinusoidal positional encodings. These are fixed (non-learned) vectors added to the input embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding_jax(max_seq_len: int, d_model: int) -> jnp.ndarray:\n",
    "    \"\"\"Create sinusoidal positional encodings for JAX.\"\"\"\n",
    "    position = jnp.arange(max_seq_len).reshape((max_seq_len, 1))\n",
    "    half_d_model = d_model // 2\n",
    "    dim_indices = jnp.arange(half_d_model).reshape((1, half_d_model))\n",
    "    scaling_factors = 10000.0 ** (2.0 * dim_indices / d_model)\n",
    "    angles = position / scaling_factors\n",
    "    sin_vals = jnp.sin(angles)\n",
    "    cos_vals = jnp.cos(angles)\n",
    "    stacked = jnp.stack([sin_vals, cos_vals], axis=2)\n",
    "    pe = stacked.reshape((max_seq_len, d_model))\n",
    "    return pe.reshape((1, max_seq_len, d_model))\n",
    "\n",
    "\n",
    "def positional_encoding_nabla(max_seq_len: int, d_model: int) -> nb.Array:\n",
    "    \"\"\"Create sinusoidal positional encodings for Nabla.\"\"\"\n",
    "    position = nb.ndarange((max_seq_len,)).reshape((max_seq_len, 1))\n",
    "    half_d_model = d_model // 2\n",
    "    dim_indices = nb.ndarange((half_d_model,)).reshape((1, half_d_model))\n",
    "    scaling_factors = 10000.0 ** (2.0 * dim_indices / d_model)\n",
    "    angles = position / scaling_factors\n",
    "    sin_vals = nb.sin(angles)\n",
    "    cos_vals = nb.cos(angles)\n",
    "    stacked = nb.stack([sin_vals, cos_vals], axis=2)\n",
    "    pe = stacked.reshape((max_seq_len, d_model))\n",
    "    return pe.reshape((1, max_seq_len, d_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scaled Dot-Product Attention\n",
    "\n",
    "This is the core mechanism of the Transformer. It computes attention scores by taking the dot product of a query vector with all key vectors, scaling the result, applying a softmax, and then using these weights to create a weighted sum of the value vectors.\n",
    "\n",
    "$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention_jax(q, k, v, mask=None):\n",
    "    \"\"\"Scaled dot-product attention for JAX.\"\"\"\n",
    "    d_k = q.shape[-1]\n",
    "    scores = jnp.matmul(q, k.transpose((0, 1, 3, 2))) / jnp.sqrt(\n",
    "        jnp.array([d_k], dtype=jnp.float32)\n",
    "    )\n",
    "    if mask is not None:\n",
    "        scores = jnp.where(mask == 0, -1e9, scores)\n",
    "    attention_weights = jax.nn.softmax(scores, axis=-1)\n",
    "    output = jnp.matmul(attention_weights, v)\n",
    "    return output\n",
    "\n",
    "\n",
    "def scaled_dot_product_attention_nabla(q, k, v, mask=None):\n",
    "    \"\"\"Scaled dot-product attention for Nabla.\"\"\"\n",
    "    d_k = q.shape[-1]\n",
    "    scores = nb.matmul(q, k.permute((0, 1, 3, 2))) / nb.sqrt(\n",
    "        nb.array([d_k], dtype=nb.DType.float32)\n",
    "    )\n",
    "    if mask is not None:\n",
    "        scores = nb.where(mask, scores, nb.full_like(scores, -1e9))\n",
    "    attention_weights = nb.softmax(scores, axis=-1)\n",
    "    output = nb.matmul(attention_weights, v)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-Head Attention\n",
    "\n",
    "Instead of performing a single attention function, we project the queries, keys, and values into multiple lower-dimensional spaces (\"heads\"). Attention is computed in parallel for each head, and the results are concatenated and projected back to the original dimension. This allows the model to jointly attend to information from different representation subspaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_head_attention_jax(x, xa, params, mask=None):\n",
    "    \"\"\"Multi-head attention for JAX.\"\"\"\n",
    "    batch_size, seq_len, d_model = x.shape\n",
    "    d_head = d_model // NUM_HEADS\n",
    "\n",
    "    q_linear = jnp.matmul(x, params[\"w_q\"])\n",
    "    k_linear = jnp.matmul(xa, params[\"w_k\"])\n",
    "    v_linear = jnp.matmul(xa, params[\"w_v\"])\n",
    "\n",
    "    q = q_linear.reshape(batch_size, seq_len, NUM_HEADS, d_head).transpose((0, 2, 1, 3))\n",
    "    k = k_linear.reshape(batch_size, -1, NUM_HEADS, d_head).transpose((0, 2, 1, 3))\n",
    "    v = v_linear.reshape(batch_size, -1, NUM_HEADS, d_head).transpose((0, 2, 1, 3))\n",
    "\n",
    "    attention_output = scaled_dot_product_attention_jax(q, k, v, mask)\n",
    "\n",
    "    attention_output = attention_output.transpose((0, 2, 1, 3)).reshape(\n",
    "        batch_size, seq_len, d_model\n",
    "    )\n",
    "    return jnp.matmul(attention_output, params[\"w_o\"])\n",
    "\n",
    "\n",
    "def multi_head_attention_nabla(x, xa, params, mask=None):\n",
    "    \"\"\"Multi-head attention for Nabla.\"\"\"\n",
    "    batch_size, seq_len, d_model = x.shape\n",
    "    d_head = d_model // NUM_HEADS\n",
    "\n",
    "    q_linear = nb.matmul(x, params[\"w_q\"])\n",
    "    k_linear = nb.matmul(xa, params[\"w_k\"])\n",
    "    v_linear = nb.matmul(xa, params[\"w_v\"])\n",
    "\n",
    "    q = q_linear.reshape((batch_size, seq_len, NUM_HEADS, d_head)).permute((0, 2, 1, 3))\n",
    "    k = k_linear.reshape((batch_size, -1, NUM_HEADS, d_head)).permute((0, 2, 1, 3))\n",
    "    v = v_linear.reshape((batch_size, -1, NUM_HEADS, d_head)).permute((0, 2, 1, 3))\n",
    "\n",
    "    attention_output = scaled_dot_product_attention_nabla(q, k, v, mask)\n",
    "\n",
    "    attention_output = attention_output.permute((0, 2, 1, 3)).reshape(\n",
    "        (batch_size, seq_len, d_model)\n",
    "    )\n",
    "    return nb.matmul(attention_output, params[\"w_o\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Position-wise Feed-Forward Network\n",
    "\n",
    "Each encoder and decoder layer contains a fully connected feed-forward network, which is applied to each position separately and identically. This consists of two linear transformations with a ReLU activation in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward_jax(x, params):\n",
    "    \"\"\"Position-wise feed-forward network for JAX.\"\"\"\n",
    "    hidden = jax.nn.relu(jnp.matmul(x, params[\"w1\"]) + params[\"b1\"])\n",
    "    output = jnp.matmul(hidden, params[\"w2\"]) + params[\"b2\"]\n",
    "    return output\n",
    "\n",
    "\n",
    "def feed_forward_nabla(x, params):\n",
    "    \"\"\"Position-wise feed-forward network for Nabla.\"\"\"\n",
    "    hidden = nb.relu(nb.matmul(x, params[\"w1\"]) + params[\"b1\"])\n",
    "    output = nb.matmul(hidden, params[\"w2\"]) + params[\"b2\"]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Layer Normalization\n",
    "\n",
    "Layer Normalization is used to stabilize the network and speed up training. We use a \"Pre-Norm\" architecture, where normalization is applied *before* each sub-layer (attention and FFN), followed by a residual connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_norm_jax(x, params, eps=1e-6):\n",
    "    \"\"\"Layer normalization for JAX.\"\"\"\n",
    "    mean = jnp.mean(x, axis=-1, keepdims=True)\n",
    "    variance = jnp.mean((x - mean) * (x - mean), axis=-1, keepdims=True)\n",
    "    normalized = (x - mean) / jnp.sqrt(variance + eps)\n",
    "    return params[\"gamma\"] * normalized + params[\"beta\"]\n",
    "\n",
    "\n",
    "def layer_norm_nabla(x, params, eps=1e-6):\n",
    "    \"\"\"Layer normalization for Nabla.\"\"\"\n",
    "    mean = nb.mean(x, axes=[-1], keep_dims=True)\n",
    "    variance = nb.mean((x - mean) * (x - mean), axes=[-1], keep_dims=True)\n",
    "    normalized = (x - mean) / nb.sqrt(variance + eps)\n",
    "    return params[\"gamma\"] * normalized + params[\"beta\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Encoder and Decoder Layers\n",
    "\n",
    "We now assemble the building blocks into complete Encoder and Decoder layers.\n",
    "\n",
    "- **Encoder Layer**: Contains a self-attention mechanism and a feed-forward network.\n",
    "- **Decoder Layer**: Contains a masked self-attention mechanism, a cross-attention mechanism (attending to the encoder's output), and a feed-forward network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- JAX Layer Implementations ---\n",
    "def encoder_layer_jax(x, params, mask):\n",
    "    norm_x = layer_norm_jax(x, params[\"norm1\"])\n",
    "    attention_output = multi_head_attention_jax(norm_x, norm_x, params[\"mha\"], mask)\n",
    "    x = x + attention_output\n",
    "\n",
    "    norm_x = layer_norm_jax(x, params[\"norm2\"])\n",
    "    ffn_output = feed_forward_jax(norm_x, params[\"ffn\"])\n",
    "    x = x + ffn_output\n",
    "    return x\n",
    "\n",
    "\n",
    "def decoder_layer_jax(x, encoder_output, params, look_ahead_mask, padding_mask):\n",
    "    norm_x = layer_norm_jax(x, params[\"norm1\"])\n",
    "    masked_attention_output = multi_head_attention_jax(\n",
    "        norm_x, norm_x, params[\"masked_mha\"], look_ahead_mask\n",
    "    )\n",
    "    x = x + masked_attention_output\n",
    "\n",
    "    norm_x = layer_norm_jax(x, params[\"norm2\"])\n",
    "    cross_attention_output = multi_head_attention_jax(\n",
    "        norm_x, encoder_output, params[\"cross_mha\"], padding_mask\n",
    "    )\n",
    "    x = x + cross_attention_output\n",
    "\n",
    "    norm_x = layer_norm_jax(x, params[\"norm3\"])\n",
    "    ffn_output = feed_forward_jax(norm_x, params[\"ffn\"])\n",
    "    x = x + ffn_output\n",
    "    return x\n",
    "\n",
    "\n",
    "# --- Nabla Layer Implementations ---\n",
    "def encoder_layer_nabla(x, params, mask):\n",
    "    normed_x = layer_norm_nabla(x, params[\"norm1\"])\n",
    "    attention_output = multi_head_attention_nabla(\n",
    "        normed_x, normed_x, params[\"mha\"], mask\n",
    "    )\n",
    "    x = x + attention_output\n",
    "\n",
    "    normed_x = layer_norm_nabla(x, params[\"norm2\"])\n",
    "    ffn_output = feed_forward_nabla(normed_x, params[\"ffn\"])\n",
    "    x = x + ffn_output\n",
    "    return x\n",
    "\n",
    "\n",
    "def decoder_layer_nabla(x, encoder_output, params, look_ahead_mask, padding_mask):\n",
    "    normed_x = layer_norm_nabla(x, params[\"norm1\"])\n",
    "    masked_attention_output = multi_head_attention_nabla(\n",
    "        normed_x, normed_x, params[\"masked_mha\"], look_ahead_mask\n",
    "    )\n",
    "    x = x + masked_attention_output\n",
    "\n",
    "    normed_x = layer_norm_nabla(x, params[\"norm2\"])\n",
    "    cross_attention_output = multi_head_attention_nabla(\n",
    "        normed_x, encoder_output, params[\"cross_mha\"], padding_mask\n",
    "    )\n",
    "    x = x + cross_attention_output\n",
    "\n",
    "    normed_x = layer_norm_nabla(x, params[\"norm3\"])\n",
    "    ffn_output = feed_forward_nabla(normed_x, params[\"ffn\"])\n",
    "    x = x + ffn_output\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Embedding Lookup\n",
    "\n",
    "Standard libraries provide a simple `embedding[ids]` lookup. To maintain a \"from-scratch\" feel and ensure a direct comparison, we implement this lookup manually using `where` operations. This converts integer token IDs into their corresponding dense vector representations from an embedding matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_lookup_jax(token_ids, embedding_matrix):\n",
    "    \"\"\"Manual embedding lookup for JAX.\"\"\"\n",
    "    return embedding_matrix[token_ids]\n",
    "\n",
    "\n",
    "def embedding_lookup_nabla(token_ids, embedding_matrix):\n",
    "    \"\"\"Manual embedding lookup for Nabla.\"\"\"\n",
    "    batch_size, seq_len = token_ids.shape\n",
    "    vocab_size, d_model = embedding_matrix.shape\n",
    "    output = nb.zeros((batch_size, seq_len, d_model))\n",
    "    for token_idx in range(vocab_size):\n",
    "        token_idx_array = nb.array([token_idx], dtype=nb.DType.int32)\n",
    "        condition = nb.equal(\n",
    "            token_ids, nb.broadcast_to(token_idx_array, token_ids.shape)\n",
    "        )\n",
    "        condition_expanded = nb.broadcast_to(\n",
    "            condition.reshape((batch_size, seq_len, 1)), (batch_size, seq_len, d_model)\n",
    "        )\n",
    "        token_embedding = embedding_matrix[token_idx : token_idx + 1, :].reshape(\n",
    "            (1, 1, d_model)\n",
    "        )\n",
    "        token_embedding_expanded = nb.broadcast_to(\n",
    "            token_embedding, (batch_size, seq_len, d_model)\n",
    "        )\n",
    "        output = nb.where(condition_expanded, token_embedding_expanded, output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Full Transformer Forward Pass\n",
    "\n",
    "Here, we combine all the preceding components into the complete encoder-decoder forward pass. This function takes the source and target token sequences, processes them through the respective stacks of layers, and produces the final output logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- JAX Full Forward Pass ---\n",
    "def transformer_forward_jax(encoder_inputs, decoder_inputs, params):\n",
    "    target_seq_len = decoder_inputs.shape[1]\n",
    "    positions = jnp.arange(target_seq_len)\n",
    "    causal_mask = positions.reshape((target_seq_len, 1)) >= positions.reshape(\n",
    "        (1, target_seq_len)\n",
    "    )\n",
    "    look_ahead_mask = causal_mask.reshape((1, 1, target_seq_len, target_seq_len))\n",
    "\n",
    "    encoder_seq_len = encoder_inputs.shape[1]\n",
    "    decoder_seq_len = decoder_inputs.shape[1]\n",
    "\n",
    "    encoder_embeddings = embedding_lookup_jax(\n",
    "        encoder_inputs, params[\"encoder\"][\"embedding\"]\n",
    "    )\n",
    "    encoder_pos_enc = params[\"pos_encoding\"][:, :encoder_seq_len, :]\n",
    "    encoder_x = encoder_embeddings + encoder_pos_enc\n",
    "\n",
    "    encoder_output = encoder_x\n",
    "    for i in range(NUM_LAYERS):\n",
    "        encoder_output = encoder_layer_jax(\n",
    "            encoder_output, params[\"encoder\"][f\"layer_{i}\"], mask=None\n",
    "        )\n",
    "    encoder_output = layer_norm_jax(encoder_output, params[\"encoder\"][\"final_norm\"])\n",
    "\n",
    "    decoder_embeddings = embedding_lookup_jax(\n",
    "        decoder_inputs, params[\"decoder\"][\"embedding\"]\n",
    "    )\n",
    "    decoder_pos_enc = params[\"pos_encoding\"][:, :decoder_seq_len, :]\n",
    "    decoder_x = decoder_embeddings + decoder_pos_enc\n",
    "\n",
    "    decoder_output = decoder_x\n",
    "    for i in range(NUM_LAYERS):\n",
    "        decoder_output = decoder_layer_jax(\n",
    "            decoder_output,\n",
    "            encoder_output,\n",
    "            params[\"decoder\"][f\"layer_{i}\"],\n",
    "            look_ahead_mask,\n",
    "            padding_mask=None,\n",
    "        )\n",
    "    decoder_output = layer_norm_jax(decoder_output, params[\"decoder\"][\"final_norm\"])\n",
    "\n",
    "    logits = jnp.matmul(decoder_output, params[\"output_linear\"])\n",
    "    return logits\n",
    "\n",
    "\n",
    "# --- Nabla Full Forward Pass ---\n",
    "def transformer_forward_nabla(encoder_inputs, decoder_inputs, params):\n",
    "    target_seq_len = decoder_inputs.shape[1]\n",
    "    positions = nb.ndarange((target_seq_len,))\n",
    "    causal_mask = nb.greater_equal(\n",
    "        nb.reshape(positions, (target_seq_len, 1)),\n",
    "        nb.reshape(positions, (1, target_seq_len)),\n",
    "    )\n",
    "    look_ahead_mask = nb.reshape(causal_mask, (1, 1, target_seq_len, target_seq_len))\n",
    "\n",
    "    encoder_seq_len = encoder_inputs.shape[1]\n",
    "    decoder_seq_len = decoder_inputs.shape[1]\n",
    "\n",
    "    encoder_embeddings = embedding_lookup_nabla(\n",
    "        encoder_inputs, params[\"encoder\"][\"embedding\"]\n",
    "    )\n",
    "    encoder_pos_enc = params[\"pos_encoding\"][:, :encoder_seq_len, :]\n",
    "    encoder_x = encoder_embeddings + encoder_pos_enc\n",
    "\n",
    "    encoder_output = encoder_x\n",
    "    for i in range(NUM_LAYERS):\n",
    "        encoder_output = encoder_layer_nabla(\n",
    "            encoder_output, params[\"encoder\"][f\"layer_{i}\"], mask=None\n",
    "        )\n",
    "    encoder_output = layer_norm_nabla(encoder_output, params[\"encoder\"][\"final_norm\"])\n",
    "\n",
    "    decoder_embeddings = embedding_lookup_nabla(\n",
    "        decoder_inputs, params[\"decoder\"][\"embedding\"]\n",
    "    )\n",
    "    decoder_pos_enc = params[\"pos_encoding\"][:, :decoder_seq_len, :]\n",
    "    decoder_x = decoder_embeddings + decoder_pos_enc\n",
    "\n",
    "    decoder_output = decoder_x\n",
    "    for i in range(NUM_LAYERS):\n",
    "        decoder_output = decoder_layer_nabla(\n",
    "            decoder_output,\n",
    "            encoder_output,\n",
    "            params[\"decoder\"][f\"layer_{i}\"],\n",
    "            look_ahead_mask,\n",
    "            padding_mask=None,\n",
    "        )\n",
    "    decoder_output = layer_norm_nabla(decoder_output, params[\"decoder\"][\"final_norm\"])\n",
    "\n",
    "    logits = nb.matmul(decoder_output, params[\"output_linear\"])\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Loss Function\n",
    "\n",
    "We use the standard cross-entropy loss to train our model. To keep the implementations comparable, we manually create one-hot encoded targets from the integer labels and then compute the loss against the model's log-softmax output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_log_softmax_jax(x, axis=-1):\n",
    "    \"\"\"Manual log softmax implementation for JAX.\"\"\"\n",
    "    x_max = jnp.max(x, axis=axis, keepdims=True)\n",
    "    x_shifted = x - x_max\n",
    "    log_sum_exp = jnp.log(jnp.sum(jnp.exp(x_shifted), axis=axis, keepdims=True))\n",
    "    return x_shifted - log_sum_exp\n",
    "\n",
    "\n",
    "def manual_log_softmax_nabla(x, axis=-1):\n",
    "    \"\"\"Manual log softmax implementation for Nabla.\"\"\"\n",
    "    x_max = nb.max(x, axes=[axis], keep_dims=True)\n",
    "    x_shifted = x - x_max\n",
    "    log_sum_exp = nb.log(nb.sum(nb.exp(x_shifted), axes=[axis], keep_dims=True))\n",
    "    return x_shifted - log_sum_exp\n",
    "\n",
    "\n",
    "def cross_entropy_loss_jax(logits, targets):\n",
    "    \"\"\"Cross-entropy loss for JAX.\"\"\"\n",
    "    batch_size, seq_len = targets.shape\n",
    "    vocab_size = logits.shape[-1]\n",
    "    targets_expanded = jnp.expand_dims(targets, -1)\n",
    "    vocab_indices = jnp.arange(vocab_size, dtype=jnp.int32).reshape((1, 1, vocab_size))\n",
    "    one_hot_targets = jnp.equal(targets_expanded, vocab_indices).astype(jnp.float32)\n",
    "    log_probs = manual_log_softmax_jax(logits)\n",
    "    cross_entropy = -jnp.sum(one_hot_targets * log_probs)\n",
    "    return cross_entropy / batch_size\n",
    "\n",
    "\n",
    "def cross_entropy_loss_nabla(logits, targets):\n",
    "    \"\"\"Cross-entropy loss for Nabla.\"\"\"\n",
    "    batch_size, seq_len = targets.shape\n",
    "    vocab_size = logits.shape[-1]\n",
    "    targets_expanded = targets.reshape((batch_size, seq_len, 1))\n",
    "    vocab_indices = nb.ndarange((vocab_size,), dtype=nb.DType.int32).reshape(\n",
    "        (1, 1, vocab_size)\n",
    "    )\n",
    "    one_hot_targets = nb.equal(targets_expanded, vocab_indices).astype(nb.DType.float32)\n",
    "    log_probs = manual_log_softmax_nabla(logits)\n",
    "    cross_entropy = -nb.sum(one_hot_targets * log_probs)\n",
    "    return cross_entropy / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Parameter Initialization\n",
    "\n",
    "We initialize the model's weights and biases. Linear layer weights are initialized using Glorot (Xavier) uniform initialization, while biases and normalization parameters are initialized to zeros and ones, respectively. Embeddings are initialized from a standard normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- JAX Parameter Initialization ---\n",
    "def _init_encoder_layer_params_jax():\n",
    "    def glorot(shape):\n",
    "        return jax.nn.initializers.glorot_uniform()(\n",
    "            jax.random.PRNGKey(int(np.random.randint(0, 1000000))), shape\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"mha\": {\n",
    "            \"w_q\": glorot((D_MODEL, D_MODEL)),\n",
    "            \"w_k\": glorot((D_MODEL, D_MODEL)),\n",
    "            \"w_v\": glorot((D_MODEL, D_MODEL)),\n",
    "            \"w_o\": glorot((D_MODEL, D_MODEL)),\n",
    "        },\n",
    "        \"ffn\": {\n",
    "            \"w1\": glorot((D_MODEL, D_FF)),\n",
    "            \"b1\": jnp.zeros(D_FF),\n",
    "            \"w2\": glorot((D_FF, D_MODEL)),\n",
    "            \"b2\": jnp.zeros(D_MODEL),\n",
    "        },\n",
    "        \"norm1\": {\"gamma\": jnp.ones(D_MODEL), \"beta\": jnp.zeros(D_MODEL)},\n",
    "        \"norm2\": {\"gamma\": jnp.ones(D_MODEL), \"beta\": jnp.zeros(D_MODEL)},\n",
    "    }\n",
    "\n",
    "\n",
    "def _init_decoder_layer_params_jax():\n",
    "    def glorot(shape):\n",
    "        return jax.nn.initializers.glorot_uniform()(\n",
    "            jax.random.PRNGKey(int(np.random.randint(0, 1000000))), shape\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"masked_mha\": {\n",
    "            \"w_q\": glorot((D_MODEL, D_MODEL)),\n",
    "            \"w_k\": glorot((D_MODEL, D_MODEL)),\n",
    "            \"w_v\": glorot((D_MODEL, D_MODEL)),\n",
    "            \"w_o\": glorot((D_MODEL, D_MODEL)),\n",
    "        },\n",
    "        \"cross_mha\": {\n",
    "            \"w_q\": glorot((D_MODEL, D_MODEL)),\n",
    "            \"w_k\": glorot((D_MODEL, D_MODEL)),\n",
    "            \"w_v\": glorot((D_MODEL, D_MODEL)),\n",
    "            \"w_o\": glorot((D_MODEL, D_MODEL)),\n",
    "        },\n",
    "        \"ffn\": {\n",
    "            \"w1\": glorot((D_MODEL, D_FF)),\n",
    "            \"b1\": jnp.zeros(D_FF),\n",
    "            \"w2\": glorot((D_FF, D_MODEL)),\n",
    "            \"b2\": jnp.zeros(D_MODEL),\n",
    "        },\n",
    "        \"norm1\": {\"gamma\": jnp.ones(D_MODEL), \"beta\": jnp.zeros(D_MODEL)},\n",
    "        \"norm2\": {\"gamma\": jnp.ones(D_MODEL), \"beta\": jnp.zeros(D_MODEL)},\n",
    "        \"norm3\": {\"gamma\": jnp.ones(D_MODEL), \"beta\": jnp.zeros(D_MODEL)},\n",
    "    }\n",
    "\n",
    "\n",
    "def init_transformer_params_jax():\n",
    "    def glorot(shape):\n",
    "        return jax.nn.initializers.glorot_uniform()(\n",
    "            jax.random.PRNGKey(int(np.random.randint(0, 1000000))), shape\n",
    "        )\n",
    "\n",
    "    def randn(shape):\n",
    "        return jax.random.normal(\n",
    "            jax.random.PRNGKey(int(np.random.randint(0, 1000000))), shape\n",
    "        )\n",
    "\n",
    "    params: dict[str, Any] = {\"encoder\": {}, \"decoder\": {}}\n",
    "    params[\"encoder\"][\"embedding\"] = randn((VOCAB_SIZE, D_MODEL))\n",
    "    params[\"decoder\"][\"embedding\"] = randn((VOCAB_SIZE, D_MODEL))\n",
    "    params[\"pos_encoding\"] = positional_encoding_jax(MAX_SEQ_LEN, D_MODEL)\n",
    "    for i in range(NUM_LAYERS):\n",
    "        params[\"encoder\"][f\"layer_{i}\"] = _init_encoder_layer_params_jax()\n",
    "    params[\"encoder\"][\"final_norm\"] = {\n",
    "        \"gamma\": jnp.ones(D_MODEL),\n",
    "        \"beta\": jnp.zeros(D_MODEL),\n",
    "    }\n",
    "    for i in range(NUM_LAYERS):\n",
    "        params[\"decoder\"][f\"layer_{i}\"] = _init_decoder_layer_params_jax()\n",
    "    params[\"decoder\"][\"final_norm\"] = {\n",
    "        \"gamma\": jnp.ones(D_MODEL),\n",
    "        \"beta\": jnp.zeros(D_MODEL),\n",
    "    }\n",
    "    params[\"output_linear\"] = glorot((D_MODEL, VOCAB_SIZE))\n",
    "    return params\n",
    "\n",
    "\n",
    "# --- Nabla Parameter Initialization ---\n",
    "def _init_encoder_layer_params_nabla():\n",
    "    return {\n",
    "        \"mha\": {\n",
    "            \"w_q\": nb.glorot_uniform((D_MODEL, D_MODEL)),\n",
    "            \"w_k\": nb.glorot_uniform((D_MODEL, D_MODEL)),\n",
    "            \"w_v\": nb.glorot_uniform((D_MODEL, D_MODEL)),\n",
    "            \"w_o\": nb.glorot_uniform((D_MODEL, D_MODEL)),\n",
    "        },\n",
    "        \"ffn\": {\n",
    "            \"w1\": nb.glorot_uniform((D_MODEL, D_FF)),\n",
    "            \"b1\": nb.zeros((D_FF,)),\n",
    "            \"w2\": nb.glorot_uniform((D_FF, D_MODEL)),\n",
    "            \"b2\": nb.zeros((D_MODEL,)),\n",
    "        },\n",
    "        \"norm1\": {\"gamma\": nb.ones((D_MODEL,)), \"beta\": nb.zeros((D_MODEL,))},\n",
    "        \"norm2\": {\"gamma\": nb.ones((D_MODEL,)), \"beta\": nb.zeros((D_MODEL,))},\n",
    "    }\n",
    "\n",
    "\n",
    "def _init_decoder_layer_params_nabla():\n",
    "    return {\n",
    "        \"masked_mha\": {\n",
    "            \"w_q\": nb.glorot_uniform((D_MODEL, D_MODEL)),\n",
    "            \"w_k\": nb.glorot_uniform((D_MODEL, D_MODEL)),\n",
    "            \"w_v\": nb.glorot_uniform((D_MODEL, D_MODEL)),\n",
    "            \"w_o\": nb.glorot_uniform((D_MODEL, D_MODEL)),\n",
    "        },\n",
    "        \"cross_mha\": {\n",
    "            \"w_q\": nb.glorot_uniform((D_MODEL, D_MODEL)),\n",
    "            \"w_k\": nb.glorot_uniform((D_MODEL, D_MODEL)),\n",
    "            \"w_v\": nb.glorot_uniform((D_MODEL, D_MODEL)),\n",
    "            \"w_o\": nb.glorot_uniform((D_MODEL, D_MODEL)),\n",
    "        },\n",
    "        \"ffn\": {\n",
    "            \"w1\": nb.glorot_uniform((D_MODEL, D_FF)),\n",
    "            \"b1\": nb.zeros((D_FF,)),\n",
    "            \"w2\": nb.glorot_uniform((D_FF, D_MODEL)),\n",
    "            \"b2\": nb.zeros((D_MODEL,)),\n",
    "        },\n",
    "        \"norm1\": {\"gamma\": nb.ones((D_MODEL,)), \"beta\": nb.zeros((D_MODEL,))},\n",
    "        \"norm2\": {\"gamma\": nb.ones((D_MODEL,)), \"beta\": nb.zeros((D_MODEL,))},\n",
    "        \"norm3\": {\"gamma\": nb.ones((D_MODEL,)), \"beta\": nb.zeros((D_MODEL,))},\n",
    "    }\n",
    "\n",
    "\n",
    "def init_transformer_params_nabla():\n",
    "    params: dict[str, Any] = {\"encoder\": {}, \"decoder\": {}}\n",
    "    params[\"encoder\"][\"embedding\"] = nb.randn((VOCAB_SIZE, D_MODEL))\n",
    "    params[\"decoder\"][\"embedding\"] = nb.randn((VOCAB_SIZE, D_MODEL))\n",
    "    params[\"pos_encoding\"] = positional_encoding_nabla(MAX_SEQ_LEN, D_MODEL)\n",
    "    for i in range(NUM_LAYERS):\n",
    "        params[\"encoder\"][f\"layer_{i}\"] = _init_encoder_layer_params_nabla()\n",
    "    params[\"encoder\"][\"final_norm\"] = {\n",
    "        \"gamma\": nb.ones((D_MODEL,)),\n",
    "        \"beta\": nb.zeros((D_MODEL,)),\n",
    "    }\n",
    "    for i in range(NUM_LAYERS):\n",
    "        params[\"decoder\"][f\"layer_{i}\"] = _init_decoder_layer_params_nabla()\n",
    "    params[\"decoder\"][\"final_norm\"] = {\n",
    "        \"gamma\": nb.ones((D_MODEL,)),\n",
    "        \"beta\": nb.zeros((D_MODEL,)),\n",
    "    }\n",
    "    params[\"output_linear\"] = nb.glorot_uniform((D_MODEL, VOCAB_SIZE))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Data Generation\n",
    "\n",
    "This function generates a batch of data for our sequence reversal task. For an input sequence like `[a, b, c]`, it produces:\n",
    "- **Encoder Input:** `[a, b, c]`\n",
    "- **Decoder Input:** `[<START>, c, b, a]` (for teacher-forcing during training)\n",
    "- **Target:** `[c, b, a, <END>]` (the ground truth for the loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reverse_dataset(batch_size):\n",
    "    \"\"\"Generates a dataset batch using NumPy first, then converts to framework-specific arrays.\"\"\"\n",
    "    base_sequences_np = np.random.randint(\n",
    "        3, VOCAB_SIZE, size=(batch_size, SOURCE_SEQ_LEN), dtype=np.int32\n",
    "    )\n",
    "    reversed_sequences_np = np.flip(base_sequences_np, axis=1)\n",
    "    encoder_input_np = base_sequences_np\n",
    "    start_tokens_np = np.ones((batch_size, 1), dtype=np.int32)  # <START> token (1)\n",
    "    decoder_input_np = np.concatenate([start_tokens_np, reversed_sequences_np], axis=1)\n",
    "    end_tokens_np = np.full((batch_size, 1), 2, dtype=np.int32)  # <END> token (2)\n",
    "    target_np = np.concatenate([reversed_sequences_np, end_tokens_np], axis=1)\n",
    "    return encoder_input_np, decoder_input_np, target_np\n",
    "\n",
    "\n",
    "def create_reverse_dataset_jax(batch_size):\n",
    "    encoder_input_np, decoder_input_np, target_np = create_reverse_dataset(batch_size)\n",
    "    return (\n",
    "        jnp.array(encoder_input_np),\n",
    "        jnp.array(decoder_input_np),\n",
    "        jnp.array(target_np),\n",
    "    )\n",
    "\n",
    "\n",
    "def create_reverse_dataset_nabla(batch_size):\n",
    "    encoder_input_np, decoder_input_np, target_np = create_reverse_dataset(batch_size)\n",
    "    return (\n",
    "        nb.Array.from_numpy(encoder_input_np),\n",
    "        nb.Array.from_numpy(decoder_input_np),\n",
    "        nb.Array.from_numpy(target_np),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Optimizer (AdamW)\n",
    "\n",
    "We implement the AdamW optimizer, which is a variant of Adam that decouples weight decay from the gradient update. This often leads to better performance. The implementation includes state initialization (`m` and `v` vectors) and the update step, which also features gradient clipping to prevent exploding gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_adamw_state_recursive(params, m_states, v_states, zeros_like_fn):\n",
    "    for key, value in params.items():\n",
    "        if isinstance(value, dict):\n",
    "            m_states[key], v_states[key] = {}, {}\n",
    "            _init_adamw_state_recursive(\n",
    "                value, m_states[key], v_states[key], zeros_like_fn\n",
    "            )\n",
    "        else:\n",
    "            m_states[key] = zeros_like_fn(value)\n",
    "            v_states[key] = zeros_like_fn(value)\n",
    "\n",
    "\n",
    "def init_adamw_state_jax(params):\n",
    "    m_states, v_states = {}, {}\n",
    "    _init_adamw_state_recursive(params, m_states, v_states, jnp.zeros_like)\n",
    "    return m_states, v_states\n",
    "\n",
    "\n",
    "def init_adamw_state_nabla(params):\n",
    "    m_states, v_states = {}, {}\n",
    "    _init_adamw_state_recursive(params, m_states, v_states, nb.zeros_like)\n",
    "    return m_states, v_states\n",
    "\n",
    "\n",
    "def adamw_step(params, grads, m, v, step, lr, framework_lib):\n",
    "    \"\"\"A generic AdamW step that can be used by both frameworks.\"\"\"\n",
    "    beta1, beta2, eps, weight_decay = 0.9, 0.999, 1e-8, 0.01\n",
    "    max_grad_norm = 1.0\n",
    "\n",
    "    total_grad_norm_sq = [0.0]\n",
    "\n",
    "    def _calc_norm(g_dict):\n",
    "        for g in g_dict.values():\n",
    "            if isinstance(g, dict):\n",
    "                _calc_norm(g)\n",
    "            else:\n",
    "                total_grad_norm_sq[0] += framework_lib.sum(g * g)\n",
    "\n",
    "    _calc_norm(grads)\n",
    "    grad_norm = framework_lib.sqrt(total_grad_norm_sq[0])\n",
    "    clip_factor = framework_lib.minimum(1.0, max_grad_norm / (grad_norm + 1e-8))\n",
    "\n",
    "    updated_params, updated_m, updated_v = {}, {}, {}\n",
    "\n",
    "    def _update(p_dict, g_dict, m_dict, v_dict, up_p, up_m, up_v):\n",
    "        for key in p_dict:\n",
    "            if isinstance(p_dict[key], dict):\n",
    "                up_p[key], up_m[key], up_v[key] = {}, {}, {}\n",
    "                _update(\n",
    "                    p_dict[key],\n",
    "                    g_dict[key],\n",
    "                    m_dict[key],\n",
    "                    v_dict[key],\n",
    "                    up_p[key],\n",
    "                    up_m[key],\n",
    "                    up_v[key],\n",
    "                )\n",
    "            else:\n",
    "                p, g, m_val, v_val = (\n",
    "                    p_dict[key],\n",
    "                    g_dict[key] * clip_factor,\n",
    "                    m_dict[key],\n",
    "                    v_dict[key],\n",
    "                )\n",
    "                up_m[key] = beta1 * m_val + (1.0 - beta1) * g\n",
    "                up_v[key] = beta2 * v_val + (1.0 - beta2) * (g * g)\n",
    "                m_corr = up_m[key] / (1.0 - beta1**step)\n",
    "                v_corr = up_v[key] / (1.0 - beta2**step)\n",
    "                up_p[key] = p - lr * (\n",
    "                    m_corr / (framework_lib.sqrt(v_corr) + eps) + weight_decay * p\n",
    "                )\n",
    "\n",
    "    _update(params, grads, m, v, updated_params, updated_m, updated_v)\n",
    "    return updated_params, updated_m, updated_v\n",
    "\n",
    "\n",
    "def adamw_step_jax(params, grads, m, v, step, lr):\n",
    "    return adamw_step(params, grads, m, v, step, lr, jnp)\n",
    "\n",
    "\n",
    "def adamw_step_nabla(params, grads, m, v, step, lr):\n",
    "    return adamw_step(params, grads, m, v, step, lr, nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. JIT-Compiled Training Step & Inference\n",
    "\n",
    "We define the core logic for a single training step and the inference (prediction) process.\n",
    "\n",
    "- **`complete_training_step`**: This function encapsulates the forward pass, loss calculation, backpropagation (gradient computation), and optimizer update. We decorate it with `@jax.jit` or `@nb.jit` to compile the entire sequence of operations into a single, highly optimized kernel for maximum performance.\n",
    "- **`predict_sequence`**: This function performs autoregressive inference. It generates the output sequence one token at a time, feeding its own prediction from the previous step back into the model as input for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- JAX Implementations ---\n",
    "@jax.jit\n",
    "def complete_training_step_jax(\n",
    "    encoder_in, decoder_in, targets, params, m_states, v_states, step\n",
    "):\n",
    "    def loss_fn(p):\n",
    "        return cross_entropy_loss_jax(\n",
    "            transformer_forward_jax(encoder_in, decoder_in, p), targets\n",
    "        )\n",
    "\n",
    "    loss_value, grads = value_and_grad(loss_fn)(params)\n",
    "    updated_params, updated_m, updated_v = adamw_step_jax(\n",
    "        params, grads, m_states, v_states, step, LEARNING_RATE\n",
    "    )\n",
    "    return updated_params, updated_m, updated_v, loss_value\n",
    "\n",
    "\n",
    "def predict_sequence_jax(encoder_input, params):\n",
    "    if encoder_input.ndim == 1:\n",
    "        encoder_input = jnp.expand_dims(encoder_input, axis=0)\n",
    "    decoder_tokens = [jnp.ones((1,), dtype=jnp.int32)]\n",
    "    decoder_input = jnp.zeros((1, TARGET_SEQ_LEN), dtype=jnp.int32)\n",
    "    decoder_input = decoder_input.at[:, 0].set(1)\n",
    "\n",
    "    for pos in range(1, TARGET_SEQ_LEN):\n",
    "        logits = transformer_forward_jax(encoder_input, decoder_input, params)\n",
    "        next_token_logits = logits[:, pos - 1, :]\n",
    "        predicted_token = jnp.argmax(next_token_logits, axis=-1).astype(jnp.int32)\n",
    "        if pos < TARGET_SEQ_LEN:\n",
    "            decoder_input = decoder_input.at[:, pos].set(predicted_token[0])\n",
    "\n",
    "    return decoder_input[0]\n",
    "\n",
    "\n",
    "# --- Nabla Implementations ---\n",
    "@nb.jit\n",
    "def complete_training_step_nabla(\n",
    "    encoder_in, decoder_in, targets, params, m_states, v_states, step\n",
    "):\n",
    "    def loss_fn(p):\n",
    "        return cross_entropy_loss_nabla(\n",
    "            transformer_forward_nabla(encoder_in, decoder_in, p), targets\n",
    "        )\n",
    "\n",
    "    loss_value, grads = nb.value_and_grad(loss_fn)(params)\n",
    "    updated_params, updated_m, updated_v = adamw_step_nabla(\n",
    "        params, grads, m_states, v_states, step, LEARNING_RATE\n",
    "    )\n",
    "    return updated_params, updated_m, updated_v, loss_value\n",
    "\n",
    "\n",
    "def predict_sequence_nabla(encoder_input, params):\n",
    "    if len(encoder_input.shape) == 1:\n",
    "        encoder_input = encoder_input.reshape((1, encoder_input.shape[0]))\n",
    "\n",
    "    decoder_tokens = [nb.ones((1,), dtype=nb.DType.int32)]\n",
    "\n",
    "    for pos in range(1, TARGET_SEQ_LEN):\n",
    "        current_decoder_input = nb.stack(decoder_tokens, axis=1)\n",
    "\n",
    "        logits = transformer_forward_nabla(encoder_input, current_decoder_input, params)\n",
    "\n",
    "        next_token_logits = logits[:, pos - 1, :]\n",
    "\n",
    "        predicted_token = nb.argmax(next_token_logits, axes=-1).astype(nb.DType.int32)\n",
    "\n",
    "        decoder_tokens.append(predicted_token)\n",
    "\n",
    "    final_sequence = nb.stack(decoder_tokens, axis=1)\n",
    "\n",
    "    return final_sequence[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. JAX Training Run\n",
    "\n",
    "This cell contains the complete training loop for the **JAX** implementation. It initializes the parameters and optimizer state, then iterates through the training epochs, calling the JIT-compiled `complete_training_step_jax` function. Finally, it evaluates the trained model on a few test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer_jax():\n",
    "    \"\"\"Main training loop for the JAX transformer.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ðŸ¤– TRAINING TRANSFORMER FROM SCRATCH WITH JAX\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(\"ðŸ”§ Initializing transformer parameters...\")\n",
    "    params = init_transformer_params_jax()\n",
    "    print(\"ðŸ“ˆ Initializing AdamW optimizer...\")\n",
    "    m_states, v_states = init_adamw_state_jax(params)\n",
    "\n",
    "    print(\"ðŸ”¥ JIT warmup (3 steps)...\")\n",
    "    for i in range(3):\n",
    "        enc_in, dec_in, targets = create_reverse_dataset_jax(BATCH_SIZE)\n",
    "        params, m_states, v_states, _ = complete_training_step_jax(\n",
    "            enc_in, dec_in, targets, params, m_states, v_states, i + 1\n",
    "        )\n",
    "    print(\"âœ… Warmup complete! Starting timed training...\\n\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    loss_history = []\n",
    "    time_history = [start_time]\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        enc_in, dec_in, targets = create_reverse_dataset_jax(BATCH_SIZE)\n",
    "        params, m_states, v_states, loss = complete_training_step_jax(\n",
    "            enc_in, dec_in, targets, params, m_states, v_states, epoch\n",
    "        )\n",
    "        loss_history.append(float(loss))\n",
    "        time_history.append(time.time())\n",
    "\n",
    "        if epoch % PRINT_INTERVAL == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch:5d} | Loss: {float(loss):.4f} | Time: {time_history[-1] - start_time:.1f}s\"\n",
    "            )\n",
    "\n",
    "    print(\n",
    "        f\"\\nâœ… JAX Training complete! Total time: {time_history[-1] - start_time:.1f}s\"\n",
    "    )\n",
    "\n",
    "    return params, loss_history, time_history\n",
    "\n",
    "\n",
    "def plot_loss_curves(\n",
    "    jax_loss_history, jax_time_history, nabla_loss_history, nabla_time_history\n",
    "):\n",
    "    \"\"\"Plot the loss curves for both JAX and Nabla implementations.\"\"\"\n",
    "    plt.figure(figsize=(15, 6))\n",
    "\n",
    "    # Plot loss vs epochs\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(jax_loss_history, label=\"JAX\")\n",
    "    plt.plot(nabla_loss_history, label=\"Nabla\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss vs Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot loss vs time - ensure equal length by truncating the longer one\n",
    "    plt.subplot(1, 2, 2)\n",
    "    min_len = min(\n",
    "        len(jax_loss_history),\n",
    "        len(jax_time_history),\n",
    "        len(nabla_loss_history),\n",
    "        len(nabla_time_history),\n",
    "    )\n",
    "    jax_times = [t - jax_time_history[0] for t in jax_time_history[:min_len]]\n",
    "    nabla_times = [t - nabla_time_history[0] for t in nabla_time_history[:min_len]]\n",
    "    plt.plot(jax_times, jax_loss_history[:min_len], label=\"JAX\")\n",
    "    plt.plot(nabla_times, nabla_loss_history[:min_len], label=\"Nabla\")\n",
    "    plt.xlabel(\"Time (seconds)\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss vs Time\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ¤– TRAINING TRANSFORMER FROM SCRATCH WITH JAX\n",
      "============================================================\n",
      "ðŸ”§ Initializing transformer parameters...\n",
      "ðŸ“ˆ Initializing AdamW optimizer...\n",
      "ðŸ”¥ JIT warmup (3 steps)...\n",
      "âœ… Warmup complete! Starting timed training...\n",
      "\n",
      "Epoch    10 | Loss: 27.8076 | Time: 0.1s\n",
      "Epoch    20 | Loss: 25.6278 | Time: 0.2s\n",
      "Epoch    30 | Loss: 23.4999 | Time: 0.3s\n",
      "Epoch    40 | Loss: 21.5969 | Time: 0.4s\n",
      "Epoch    50 | Loss: 20.3087 | Time: 0.5s\n",
      "Epoch    60 | Loss: 18.4939 | Time: 0.6s\n",
      "Epoch    70 | Loss: 17.1803 | Time: 0.7s\n",
      "Epoch    80 | Loss: 15.1316 | Time: 0.8s\n",
      "Epoch    90 | Loss: 13.2815 | Time: 0.9s\n",
      "Epoch   100 | Loss: 11.2834 | Time: 0.9s\n",
      "Epoch   110 | Loss: 9.7185 | Time: 1.0s\n",
      "Epoch   120 | Loss: 7.2969 | Time: 1.1s\n",
      "Epoch   130 | Loss: 5.9019 | Time: 1.2s\n",
      "Epoch   140 | Loss: 4.1955 | Time: 1.3s\n",
      "Epoch   150 | Loss: 3.0798 | Time: 1.5s\n",
      "Epoch   160 | Loss: 2.4024 | Time: 1.5s\n",
      "Epoch   170 | Loss: 1.5696 | Time: 1.6s\n",
      "Epoch   180 | Loss: 0.9398 | Time: 1.7s\n",
      "Epoch   190 | Loss: 0.7780 | Time: 1.8s\n",
      "Epoch   200 | Loss: 0.5416 | Time: 1.9s\n",
      "Epoch   210 | Loss: 0.3281 | Time: 2.0s\n",
      "Epoch   220 | Loss: 0.2672 | Time: 2.1s\n",
      "Epoch   230 | Loss: 0.2368 | Time: 2.2s\n",
      "Epoch   240 | Loss: 0.1338 | Time: 2.2s\n",
      "Epoch   250 | Loss: 0.1160 | Time: 2.3s\n",
      "Epoch   260 | Loss: 0.0915 | Time: 2.4s\n",
      "Epoch   270 | Loss: 0.0970 | Time: 2.5s\n",
      "Epoch   280 | Loss: 0.0725 | Time: 2.6s\n",
      "Epoch   290 | Loss: 0.0759 | Time: 2.7s\n",
      "Epoch   300 | Loss: 0.0428 | Time: 2.8s\n",
      "Epoch   310 | Loss: 0.0300 | Time: 2.8s\n",
      "Epoch   320 | Loss: 0.0254 | Time: 2.9s\n",
      "Epoch   330 | Loss: 0.0179 | Time: 3.0s\n",
      "Epoch   340 | Loss: 0.0185 | Time: 3.1s\n",
      "Epoch   350 | Loss: 0.0151 | Time: 3.2s\n",
      "Epoch   360 | Loss: 0.0134 | Time: 3.3s\n",
      "Epoch   370 | Loss: 0.0137 | Time: 3.4s\n",
      "Epoch   380 | Loss: 0.0118 | Time: 3.5s\n",
      "Epoch   390 | Loss: 0.0143 | Time: 3.5s\n",
      "Epoch   400 | Loss: 0.0091 | Time: 3.6s\n",
      "Epoch   410 | Loss: 0.0081 | Time: 3.7s\n",
      "Epoch   420 | Loss: 0.0074 | Time: 3.8s\n",
      "Epoch   430 | Loss: 0.0067 | Time: 3.9s\n",
      "Epoch   440 | Loss: 0.0064 | Time: 4.0s\n",
      "Epoch   450 | Loss: 0.0102 | Time: 4.1s\n",
      "Epoch   460 | Loss: 0.0067 | Time: 4.2s\n",
      "Epoch   470 | Loss: 0.0078 | Time: 4.3s\n",
      "Epoch   480 | Loss: 0.0067 | Time: 4.4s\n",
      "Epoch   490 | Loss: 0.0228 | Time: 4.5s\n",
      "Epoch   500 | Loss: 0.0086 | Time: 4.6s\n",
      "\n",
      "âœ… JAX Training complete! Total time: 4.6s\n"
     ]
    }
   ],
   "source": [
    "# Run the JAX training and store results\n",
    "jax_params, jax_loss_history, jax_time_history = train_transformer_jax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Nabla Training Run\n",
    "\n",
    "This cell contains the complete training loop for the **Nabla** implementation. It follows the same structure as the JAX version, using the `_nabla` suffixed functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer_nabla():\n",
    "    \"\"\"Main training loop for the Nabla transformer.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ðŸ¤– TRAINING TRANSFORMER FROM SCRATCH WITH NABLA\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(\"ðŸ”§ Initializing transformer parameters...\")\n",
    "    params = init_transformer_params_nabla()\n",
    "    print(\"ðŸ“ˆ Initializing AdamW optimizer...\")\n",
    "    m_states, v_states = init_adamw_state_nabla(params)\n",
    "\n",
    "    print(\"ðŸ”¥ JIT warmup (3 steps)...\")\n",
    "    for i in range(3):\n",
    "        enc_in, dec_in, targets = create_reverse_dataset_nabla(BATCH_SIZE)\n",
    "        params, m_states, v_states, _ = complete_training_step_nabla(\n",
    "            enc_in, dec_in, targets, params, m_states, v_states, i + 1\n",
    "        )\n",
    "    print(\"âœ… Warmup complete! Starting timed training...\\n\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    loss_history = []\n",
    "    time_history = [start_time]\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        enc_in, dec_in, targets = create_reverse_dataset_nabla(BATCH_SIZE)\n",
    "        params, m_states, v_states, loss = complete_training_step_nabla(\n",
    "            enc_in, dec_in, targets, params, m_states, v_states, epoch\n",
    "        )\n",
    "        loss_history.append(float(loss.to_numpy()))\n",
    "        time_history.append(time.time())\n",
    "\n",
    "        if epoch % PRINT_INTERVAL == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch:5d} | Loss: {loss.to_numpy():.4f} | Time: {time_history[-1] - start_time:.1f}s\"\n",
    "            )\n",
    "\n",
    "    print(\n",
    "        f\"\\nâœ… Nabla Training complete! Total time: {time_history[-1] - start_time:.1f}s\"\n",
    "    )\n",
    "\n",
    "    return params, loss_history, time_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ¤– TRAINING TRANSFORMER FROM SCRATCH WITH NABLA\n",
      "============================================================\n",
      "ðŸ”§ Initializing transformer parameters...\n",
      "ðŸ“ˆ Initializing AdamW optimizer...\n",
      "ðŸ”¥ JIT warmup (3 steps)...\n",
      "âœ… Warmup complete! Starting timed training...\n",
      "\n",
      "Epoch    10 | Loss: 28.5808 | Time: 0.1s\n",
      "Epoch    20 | Loss: 27.7783 | Time: 0.2s\n",
      "Epoch    30 | Loss: 26.5810 | Time: 0.3s\n",
      "Epoch    40 | Loss: 24.3916 | Time: 0.3s\n",
      "Epoch    50 | Loss: 22.2699 | Time: 0.5s\n",
      "Epoch    60 | Loss: 20.6258 | Time: 0.6s\n",
      "Epoch    70 | Loss: 19.4857 | Time: 0.7s\n",
      "Epoch    80 | Loss: 17.4208 | Time: 0.8s\n",
      "Epoch    90 | Loss: 15.8058 | Time: 0.8s\n",
      "Epoch   100 | Loss: 13.9562 | Time: 0.9s\n",
      "Epoch   110 | Loss: 11.5999 | Time: 1.0s\n",
      "Epoch   120 | Loss: 9.1855 | Time: 1.1s\n",
      "Epoch   130 | Loss: 6.5512 | Time: 1.2s\n",
      "Epoch   140 | Loss: 3.6793 | Time: 1.3s\n",
      "Epoch   150 | Loss: 1.9361 | Time: 1.4s\n",
      "Epoch   160 | Loss: 1.0085 | Time: 1.4s\n",
      "Epoch   170 | Loss: 0.7367 | Time: 1.5s\n",
      "Epoch   180 | Loss: 0.3662 | Time: 1.6s\n",
      "Epoch   190 | Loss: 0.2475 | Time: 1.7s\n",
      "Epoch   200 | Loss: 0.1554 | Time: 1.8s\n",
      "Epoch   210 | Loss: 0.1893 | Time: 1.9s\n",
      "Epoch   220 | Loss: 0.0946 | Time: 1.9s\n",
      "Epoch   230 | Loss: 0.1244 | Time: 2.0s\n",
      "Epoch   240 | Loss: 0.1072 | Time: 2.1s\n",
      "Epoch   250 | Loss: 0.0600 | Time: 2.2s\n",
      "Epoch   260 | Loss: 0.0586 | Time: 2.3s\n",
      "Epoch   270 | Loss: 0.0534 | Time: 2.4s\n",
      "Epoch   280 | Loss: 0.0279 | Time: 2.4s\n",
      "Epoch   290 | Loss: 0.0254 | Time: 2.5s\n",
      "Epoch   300 | Loss: 0.0194 | Time: 2.6s\n",
      "Epoch   310 | Loss: 0.0178 | Time: 2.7s\n",
      "Epoch   320 | Loss: 0.0201 | Time: 2.8s\n",
      "Epoch   330 | Loss: 0.0170 | Time: 2.9s\n",
      "Epoch   340 | Loss: 0.0211 | Time: 3.0s\n",
      "Epoch   350 | Loss: 0.0158 | Time: 3.0s\n",
      "Epoch   360 | Loss: 0.0133 | Time: 3.1s\n",
      "Epoch   370 | Loss: 0.0132 | Time: 3.2s\n",
      "Epoch   380 | Loss: 0.0107 | Time: 3.3s\n",
      "Epoch   390 | Loss: 0.0115 | Time: 3.4s\n",
      "Epoch   400 | Loss: 0.0411 | Time: 3.4s\n",
      "Epoch   410 | Loss: 0.0114 | Time: 3.5s\n",
      "Epoch   420 | Loss: 0.0182 | Time: 3.6s\n",
      "Epoch   430 | Loss: 0.0091 | Time: 3.7s\n",
      "Epoch   440 | Loss: 0.0102 | Time: 3.8s\n",
      "Epoch   450 | Loss: 0.0080 | Time: 3.8s\n",
      "Epoch   460 | Loss: 0.0081 | Time: 3.9s\n",
      "Epoch   470 | Loss: 0.0084 | Time: 4.0s\n",
      "Epoch   480 | Loss: 0.0074 | Time: 4.1s\n",
      "Epoch   490 | Loss: 0.0089 | Time: 4.2s\n",
      "Epoch   500 | Loss: 0.0075 | Time: 4.2s\n",
      "\n",
      "âœ… Nabla Training complete! Total time: 4.2s\n"
     ]
    }
   ],
   "source": [
    "# Run the Nabla training and store results\n",
    "nabla_params, nabla_loss_history, nabla_time_history = train_transformer_nabla()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Loss Curves Visualization\n",
    "\n",
    "Now that we've trained both models, let's visualize and compare their training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curves for both implementations\n",
    "plot_loss_curves(\n",
    "    jax_loss_history, jax_time_history, nabla_loss_history, nabla_time_history\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Final Evaluation\n",
    "\n",
    "Let's evaluate both models on the same test examples to compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ§ª FINAL JAX EVALUATION\n",
      "============================================================\n",
      "Example 1:\n",
      "  Input:           [ 3 16  6  6  3  4 10  4  8]\n",
      "  Expected output: [ 8  4 10  4  3  6  6 16  3  2]\n",
      "  Predicted:       [ 8  4 10  4  3  6  6 16  3  2]\n",
      "  Correct:         âœ… YES\n",
      "Example 2:\n",
      "  Input:           [ 6  7 14  6  3 17  6 15  4]\n",
      "  Expected output: [ 4 15  6 17  3  6 14  7  6  2]\n",
      "  Predicted:       [ 4 15  6 17  3  6 14  7  6  2]\n",
      "  Correct:         âœ… YES\n",
      "Example 3:\n",
      "  Input:           [15 12 13 15 13  8  7  4  3]\n",
      "  Expected output: [ 3  4  7  8 13 15 13 12 15  2]\n",
      "  Predicted:       [ 3  4  7  8 13 15 13 12 15  2]\n",
      "  Correct:         âœ… YES\n",
      "Example 4:\n",
      "  Input:           [ 8  4 17  3 12 10  8  5 14]\n",
      "  Expected output: [14  5  8 10 12  3 17  4  8  2]\n",
      "  Predicted:       [14  5  8 10 12  3 17  4  8  2]\n",
      "  Correct:         âœ… YES\n",
      "Example 5:\n",
      "  Input:           [ 4 19 17 18  6 12 11 15 10]\n",
      "  Expected output: [10 15 11 12  6 18 17 19  4  2]\n",
      "  Predicted:       [10 15 11 12  6 18 17 19  4  2]\n",
      "  Correct:         âœ… YES\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª FINAL NABLA EVALUATION\n",
      "============================================================\n",
      "Example 1:\n",
      "  Input:           [ 5  3  4  9  4 13 14 11 14]:\u001b[95mi32[9]\u001b[0m\n",
      "  Expected output: [14 11 14 13  4  9  4  3  5  2]:\u001b[95mi32[10]\u001b[0m\n",
      "  Predicted:       [14 11 14 13  4  9  4  3  5  2]:\u001b[95mi32[10]\u001b[0m\n",
      "  Correct:         âœ… YES\n",
      "Example 2:\n",
      "  Input:           [16 18  6 17  9 17  3  6  7]:\u001b[95mi32[9]\u001b[0m\n",
      "  Expected output: [ 7  6  3 17  9 17  6 18 16  2]:\u001b[95mi32[10]\u001b[0m\n",
      "  Predicted:       [ 7  6  3 17  9 17  6 18 16  2]:\u001b[95mi32[10]\u001b[0m\n",
      "  Correct:         âœ… YES\n",
      "Example 3:\n",
      "  Input:           [12  4  3 14 11 12 16 15  8]:\u001b[95mi32[9]\u001b[0m\n",
      "  Expected output: [ 8 15 16 12 11 14  3  4 12  2]:\u001b[95mi32[10]\u001b[0m\n",
      "  Predicted:       [ 8 15 16 12 11 14  3  4 12  2]:\u001b[95mi32[10]\u001b[0m\n",
      "  Correct:         âœ… YES\n",
      "Example 4:\n",
      "  Input:           [17 18  9  5  4  8  9  3 19]:\u001b[95mi32[9]\u001b[0m\n",
      "  Expected output: [19  3  9  8  4  5  9 18 17  2]:\u001b[95mi32[10]\u001b[0m\n",
      "  Predicted:       [19  3  9  8  4  5  9 18 17  2]:\u001b[95mi32[10]\u001b[0m\n",
      "  Correct:         âœ… YES\n",
      "Example 5:\n",
      "  Input:           [ 4 16  7  6  7 16 16 12 11]:\u001b[95mi32[9]\u001b[0m\n",
      "  Expected output: [11 12 16 16  7  6  7 16  4  2]:\u001b[95mi32[10]\u001b[0m\n",
      "  Predicted:       [11 12 16 16  7  6  7 16  4  2]:\u001b[95mi32[10]\u001b[0m\n",
      "  Correct:         âœ… YES\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(params, predict_fn, create_dataset_fn, framework_name):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"ðŸ§ª FINAL {framework_name.upper()} EVALUATION\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Test on 5 random examples\n",
    "    for i in range(5):\n",
    "        test_enc_in, _, test_target = create_dataset_fn(1)\n",
    "        prediction = predict_fn(test_enc_in[0], params)\n",
    "\n",
    "        if framework_name == \"jax\":\n",
    "            is_correct = jnp.array_equal(prediction[1:], test_target[0])\n",
    "            print(f\"Example {i + 1}:\")\n",
    "            print(f\"  Input:           {test_enc_in[0]}\")\n",
    "            print(f\"  Expected output: {test_target[0]}\")\n",
    "            print(f\"  Predicted:       {prediction[1:]}\")\n",
    "            print(f\"  Correct:         {'âœ… YES' if is_correct else 'âŒ NO'}\")\n",
    "        else:  # nabla\n",
    "            is_correct = np.array_equal(\n",
    "                prediction[1:].to_numpy(), test_target[0].to_numpy()\n",
    "            )\n",
    "            print(f\"Example {i + 1}:\")\n",
    "            print(f\"  Input:           {test_enc_in[0]}\")\n",
    "            print(f\"  Expected output: {test_target[0]}\")\n",
    "            print(f\"  Predicted:       {prediction[1:]}\")\n",
    "            print(f\"  Correct:         {'âœ… YES' if is_correct else 'âŒ NO'}\")\n",
    "\n",
    "\n",
    "# Evaluate JAX model\n",
    "evaluate_model(jax_params, predict_sequence_jax, create_reverse_dataset_jax, \"jax\")\n",
    "\n",
    "# Evaluate Nabla model\n",
    "evaluate_model(\n",
    "    nabla_params, predict_sequence_nabla, create_reverse_dataset_nabla, \"nabla\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nabla-env)",
   "language": "python",
   "name": "nabla-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

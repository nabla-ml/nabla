# Functional

Stateless functional API for neural network operations.

## Activations

Pure activation functions: `relu`, `gelu`, `silu`, `sigmoid`, `softmax`, `tanh`.

```{toctree}
:maxdepth: 1
:hidden:

activations/index
```

## Losses

Loss functions: `cross_entropy`, `mse_loss`, `binary_cross_entropy`.

```{toctree}
:maxdepth: 1
:hidden:

losses/index
```

## Layers

Stateless layer functions: `linear`, `layer_norm`, weight initializers (`xavier_uniform`, `he_normal`).

```{toctree}
:maxdepth: 1
:hidden:

layers/index
```

{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0",
   "mimetype": "text/x-python",
   "file_extension": ".py"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a5e722",
   "metadata": {},
   "source": [
    "# Example 11: QLoRA Fine-Tuning MVP\n",
    "\n",
    "This example mirrors LoRA fine-tuning with quantized base weights:\n",
    "- NF4 quantization of frozen weights\n",
    "- LoRA adapter training on quantized weights\n",
    "- quick quality checks (loss drop + quantization error)"
   ]
  },
  {
   "cell_type": "code",
   "id": "5971796d",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import nabla as nb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6053bd3e",
   "metadata": {},
   "source": [
    "## 1. Synthetic Data Helper"
   ]
  },
  {
   "cell_type": "code",
   "id": "7555337c",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_regression_data(\n",
    "    n_samples: int, in_dim: int, out_dim: int\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    rng = np.random.default_rng(321)\n",
    "    x = rng.normal(size=(n_samples, in_dim)).astype(np.float32)\n",
    "\n",
    "    w_base = rng.normal(size=(in_dim, out_dim)).astype(np.float32) * 0.4\n",
    "    u = rng.normal(size=(in_dim, 4)).astype(np.float32)\n",
    "    v = rng.normal(size=(4, out_dim)).astype(np.float32)\n",
    "    delta = 0.30 * (u @ v)\n",
    "\n",
    "    y = x @ (w_base + delta)\n",
    "    return x, y.astype(np.float32), w_base.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925574e9",
   "metadata": {},
   "source": [
    "## 2. Train QLoRA Adapter"
   ]
  },
  {
   "cell_type": "code",
   "id": "1c6d5f30",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    in_dim, out_dim = 64, 32\n",
    "    rank = 8\n",
    "    alpha = 16.0\n",
    "    learning_rate = 2e-2\n",
    "    steps = 120\n",
    "\n",
    "    x_np, y_np, w_base_np = make_regression_data(\n",
    "        n_samples=512, in_dim=in_dim, out_dim=out_dim\n",
    "    )\n",
    "\n",
    "    x = nb.Tensor.from_dlpack(x_np)\n",
    "    y = nb.Tensor.from_dlpack(y_np)\n",
    "    frozen_weight = nb.Tensor.from_dlpack(w_base_np)\n",
    "\n",
    "    qweight = nb.nn.finetune.quantize_nf4(frozen_weight, block_size=64)\n",
    "    dense_recon = nb.nn.finetune.dequantize_nf4(qweight)\n",
    "    quant_rel_err = float(\n",
    "        np.linalg.norm(dense_recon.to_numpy() - frozen_weight.to_numpy())\n",
    "        / (np.linalg.norm(frozen_weight.to_numpy()) + 1e-8)\n",
    "    )\n",
    "    print(f\"NF4 relative reconstruction error: {quant_rel_err:.4f}\")\n",
    "\n",
    "    lora_params = nb.nn.finetune.init_lora_adapter(\n",
    "        frozen_weight, rank=rank, init_std=0.01\n",
    "    )\n",
    "    opt_state = nb.nn.optim.adamw_init(lora_params)\n",
    "\n",
    "    def loss_fn(adapter, batch_x, batch_y):\n",
    "        pred = nb.nn.finetune.qlora_linear(\n",
    "            batch_x,\n",
    "            qweight,\n",
    "            adapter,\n",
    "            alpha=alpha,\n",
    "            compute_dtype=nb.DType.float32,\n",
    "        )\n",
    "        diff = pred - batch_y\n",
    "        return nb.mean(diff * diff)\n",
    "\n",
    "    def train_step(adapter, optimizer_state, batch_x, batch_y):\n",
    "        loss, grads = nb.value_and_grad(loss_fn, argnums=0, realize=False)(\n",
    "            adapter, batch_x, batch_y\n",
    "        )\n",
    "        new_adapter, new_state = nb.nn.optim.adamw_update(\n",
    "            adapter,\n",
    "            grads,\n",
    "            optimizer_state,\n",
    "            lr=learning_rate,\n",
    "            weight_decay=0.0,\n",
    "        )\n",
    "        to_realize = [loss]\n",
    "        to_realize.extend(t for t in nb.tree_leaves(grads) if isinstance(t, nb.Tensor))\n",
    "        to_realize.extend(\n",
    "            t for t in nb.tree_leaves(new_adapter) if isinstance(t, nb.Tensor)\n",
    "        )\n",
    "        to_realize.extend(\n",
    "            t for t in nb.tree_leaves(new_state) if isinstance(t, nb.Tensor)\n",
    "        )\n",
    "        nb.realize_all(*to_realize)\n",
    "        return loss, new_adapter, new_state\n",
    "\n",
    "    initial_loss = float(loss_fn(lora_params, x, y).to_numpy())\n",
    "    print(f\"Initial loss: {initial_loss:.6f}\")\n",
    "\n",
    "    for step in range(steps):\n",
    "        loss, lora_params, opt_state = train_step(lora_params, opt_state, x, y)\n",
    "        if (step + 1) % 50 == 0:\n",
    "            print(f\"Step {step + 1:>3d}: loss={float(loss.to_numpy()):.6f}\")\n",
    "\n",
    "    final_loss = float(loss_fn(lora_params, x, y).to_numpy())\n",
    "    print(f\"Final loss:   {final_loss:.6f}\")\n",
    "\n",
    "    if final_loss >= initial_loss:\n",
    "        raise RuntimeError(\"QLoRA training did not reduce loss.\")\n",
    "\n",
    "    print(\"âœ… QLoRA MVP finished successfully.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ]
}

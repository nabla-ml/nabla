{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0",
   "mimetype": "text/x-python",
   "file_extension": ".py"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dc91d32",
   "metadata": {},
   "source": [
    "# Example 1: Tensors and Operations\n",
    "\n",
    "Welcome to Nabla! This example introduces the core building block of\n",
    "the library: the **Tensor**. Nabla tensors are lazy by default — operations\n",
    "build a computation graph that is evaluated only when you request the result\n",
    "(e.g., by printing or calling `.realize()`).\n",
    "\n",
    "Let's start by importing Nabla and NumPy."
   ]
  },
  {
   "cell_type": "code",
   "id": "a022dd54",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import nabla as nb\n",
    "\n",
    "print(\"Nabla imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eec80f",
   "metadata": {},
   "source": [
    "## 1. Creating Tensors\n",
    "\n",
    "There are several ways to create tensors in Nabla:\n",
    "\n",
    "1. **From NumPy arrays** via `nb.Tensor.from_dlpack()` (works with any DLPack source)\n",
    "2. **Factory functions** like `nb.zeros()`, `nb.ones()`, `nb.arange()`, `nb.uniform()`\n",
    "3. **Constants** via `nb.constant()`"
   ]
  },
  {
   "cell_type": "code",
   "id": "8ff27513",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From NumPy arrays\n",
    "np_array = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=np.float32)\n",
    "x = nb.Tensor.from_dlpack(np_array)\n",
    "print(\"From NumPy:\")\n",
    "print(x)\n",
    "print(f\"  Shape: {x.shape}, Dtype: {x.dtype}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "4685fcf9",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factory functions — zeros, ones, full\n",
    "z = nb.zeros((2, 3))\n",
    "o = nb.ones((2, 3))\n",
    "f = nb.full((2, 3), 3.14)\n",
    "print(\"Zeros:\", z)\n",
    "print(\"Ones: \", o)\n",
    "print(\"Full: \", f)"
   ]
  },
  {
   "cell_type": "code",
   "id": "afc65942",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranges and random tensors\n",
    "r = nb.arange(0, 6, dtype=nb.DType.float32)\n",
    "u = nb.uniform((2, 3), low=-1.0, high=1.0)\n",
    "g = nb.gaussian((2, 3), mean=0.0, std=1.0)\n",
    "print(\"Arange:  \", r)\n",
    "print(\"Uniform: \", u)\n",
    "print(\"Gaussian:\", g)"
   ]
  },
  {
   "cell_type": "code",
   "id": "22fcfce4",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants from python lists (via numpy)\n",
    "c = nb.constant(np.array([10.0, 20.0, 30.0], dtype=np.float32))\n",
    "print(\"Constant:\", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdd18b2",
   "metadata": {},
   "source": [
    "## 2. Tensor Properties\n",
    "\n",
    "Every tensor carries metadata about its shape, dtype, and device."
   ]
  },
  {
   "cell_type": "code",
   "id": "08fccd4d",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nb.uniform((3, 4, 5))\n",
    "print(f\"Shape:  {x.shape}\")\n",
    "print(f\"Dtype:  {x.dtype}\")\n",
    "print(f\"Device: {x.device}\")\n",
    "print(f\"Rank:   {x.ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3048b431",
   "metadata": {},
   "source": [
    "## 3. Arithmetic Operations\n",
    "\n",
    "Nabla supports standard arithmetic via Python operators and named functions.\n",
    "All operations are lazy — they build a graph that is evaluated on demand."
   ]
  },
  {
   "cell_type": "code",
   "id": "16526008",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nb.Tensor.from_dlpack(np.array([1.0, 2.0, 3.0], dtype=np.float32))\n",
    "b = nb.Tensor.from_dlpack(np.array([4.0, 5.0, 6.0], dtype=np.float32))\n",
    "\n",
    "print(\"a:    \", a)\n",
    "print(\"b:    \", b)\n",
    "print(\"a + b:\", a + b)\n",
    "print(\"a - b:\", a - b)\n",
    "print(\"a * b:\", a * b)\n",
    "print(\"a / b:\", a / b)\n",
    "print(\"a ** 2:\", a ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "id": "21ecee50",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Named function equivalents\n",
    "print(\"nb.add(a, b):\", nb.add(a, b))\n",
    "print(\"nb.mul(a, b):\", nb.mul(a, b))\n",
    "print(\"nb.sub(a, b):\", nb.sub(a, b))\n",
    "print(\"nb.div(a, b):\", nb.div(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be73850",
   "metadata": {},
   "source": [
    "## 4. Element-wise Unary Operations\n",
    "\n",
    "Nabla provides a rich set of element-wise functions."
   ]
  },
  {
   "cell_type": "code",
   "id": "8be4ead5",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nb.Tensor.from_dlpack(np.array([0.0, 0.5, 1.0, 1.5, 2.0], dtype=np.float32))\n",
    "print(\"x:       \", x)\n",
    "print(\"exp(x):  \", nb.exp(x))\n",
    "print(\"log(x+1):\", nb.log(x + 1.0))\n",
    "print(\"sqrt(x): \", nb.sqrt(x))\n",
    "print(\"sin(x):  \", nb.sin(x))\n",
    "print(\"cos(x):  \", nb.cos(x))\n",
    "print(\"tanh(x): \", nb.tanh(x))"
   ]
  },
  {
   "cell_type": "code",
   "id": "6c06c3ea",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions\n",
    "x = nb.Tensor.from_dlpack(np.array([-2.0, -1.0, 0.0, 1.0, 2.0], dtype=np.float32))\n",
    "print(\"x:       \", x)\n",
    "print(\"relu(x): \", nb.relu(x))\n",
    "print(\"sigmoid:\", nb.sigmoid(x))\n",
    "print(\"gelu(x): \", nb.gelu(x))\n",
    "print(\"silu(x): \", nb.silu(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb69ff",
   "metadata": {},
   "source": [
    "## 5. Matrix Operations\n",
    "\n",
    "Matrix multiplication is a first-class operation in Nabla."
   ]
  },
  {
   "cell_type": "code",
   "id": "253779aa",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nb.uniform((3, 4))\n",
    "B = nb.uniform((4, 5))\n",
    "C = nb.matmul(A, B)  # or A @ B\n",
    "print(f\"A shape: {A.shape}\")\n",
    "print(f\"B shape: {B.shape}\")\n",
    "print(f\"A @ B shape: {C.shape}\")\n",
    "print(\"A @ B:\\n\", C)"
   ]
  },
  {
   "cell_type": "code",
   "id": "1cfbd8bb",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batched matmul\n",
    "batch_A = nb.uniform((2, 3, 4))\n",
    "batch_B = nb.uniform((2, 4, 5))\n",
    "batch_C = batch_A @ batch_B\n",
    "print(f\"Batched matmul: {batch_A.shape} @ {batch_B.shape} = {batch_C.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "148c2436",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer product via broadcasting: v1[:, None] * v2[None, :]\n",
    "v1 = nb.Tensor.from_dlpack(np.array([1.0, 2.0, 3.0], dtype=np.float32))\n",
    "v2 = nb.Tensor.from_dlpack(np.array([4.0, 5.0], dtype=np.float32))\n",
    "outer = nb.unsqueeze(v1, axis=1) * nb.unsqueeze(v2, axis=0)\n",
    "print(f\"Outer product ({v1.shape} x {v2.shape}):\")\n",
    "print(outer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab07252",
   "metadata": {},
   "source": [
    "## 6. Reduction Operations\n",
    "\n",
    "Reduce along one or more axes (or all axes for a scalar result)."
   ]
  },
  {
   "cell_type": "code",
   "id": "2f65b006",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nb.Tensor.from_dlpack(\n",
    "    np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=np.float32)\n",
    ")\n",
    "print(\"x:\\n\", x)\n",
    "print()\n",
    "\n",
    "# Full reductions\n",
    "print(\"sum(x):  \", nb.reduce_sum(x))\n",
    "print(\"mean(x): \", nb.mean(x))\n",
    "print(\"max(x):  \", nb.reduce_max(x))\n",
    "print(\"min(x):  \", nb.reduce_min(x))"
   ]
  },
  {
   "cell_type": "code",
   "id": "150e9c1b",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Axis-specific reductions\n",
    "print(\"sum(axis=0):\", nb.reduce_sum(x, axis=0))  # Sum columns\n",
    "print(\"sum(axis=1):\", nb.reduce_sum(x, axis=1))  # Sum rows\n",
    "print(\"mean(axis=1):\", nb.mean(x, axis=1))\n",
    "print(\"max(axis=0): \", nb.reduce_max(x, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "id": "47c93f1b",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keepdims preserves the reduced dimension\n",
    "print(\"sum(axis=1, keepdims=True):\", nb.reduce_sum(x, axis=1, keepdims=True))\n",
    "print(f\"  Shape: {nb.reduce_sum(x, axis=1, keepdims=True).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "981c1790",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argmax / Argmin\n",
    "print(\"argmax(axis=1):\", nb.argmax(x, axis=1))\n",
    "print(\"argmin(axis=0):\", nb.argmin(x, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cca5fc",
   "metadata": {},
   "source": [
    "## 7. Shape Manipulation\n",
    "\n",
    "Nabla supports reshaping, transposing, squeezing, and more — all as lazy ops."
   ]
  },
  {
   "cell_type": "code",
   "id": "606a1108",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nb.arange(0, 12, dtype=nb.DType.float32)\n",
    "print(f\"Original: shape={x.shape}\")\n",
    "print(x)\n",
    "\n",
    "# Reshape\n",
    "r = nb.reshape(x, (3, 4))\n",
    "print(f\"\\nReshaped to (3, 4):\")\n",
    "print(r)\n",
    "\n",
    "# Flatten\n",
    "f = nb.flatten(r)\n",
    "print(f\"\\nFlattened back: shape={f.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "87dcf179",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose and permute\n",
    "m = nb.uniform((2, 3, 4))\n",
    "print(f\"Original shape:   {m.shape}\")\n",
    "print(f\"Swap axes (1,2):  {nb.swap_axes(m, 1, 2).shape}\")\n",
    "print(f\"Permute (2,0,1):  {nb.permute(m, (2, 0, 1)).shape}\")\n",
    "print(f\"Move axis 2→0:    {nb.moveaxis(m, 2, 0).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "04b4200e",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squeeze and unsqueeze\n",
    "x = nb.ones((1, 3, 1, 4))\n",
    "print(f\"Original:       {x.shape}\")\n",
    "print(f\"Squeeze(0):     {nb.squeeze(x, axis=0).shape}\")\n",
    "print(f\"Squeeze(2):     {nb.squeeze(x, axis=2).shape}\")\n",
    "\n",
    "y = nb.ones((3, 4))\n",
    "print(f\"Unsqueeze(0):   {nb.unsqueeze(y, axis=0).shape}\")\n",
    "print(f\"Unsqueeze(1):   {nb.unsqueeze(y, axis=1).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411ff664",
   "metadata": {},
   "source": [
    "## 8. Concatenation and Stacking"
   ]
  },
  {
   "cell_type": "code",
   "id": "8b28fa06",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nb.ones((2, 3))\n",
    "b = nb.zeros((2, 3))\n",
    "print(\"Concatenate (axis=0):\", nb.concatenate([a, b], axis=0).shape)\n",
    "print(\"Concatenate (axis=1):\", nb.concatenate([a, b], axis=1).shape)\n",
    "print(\"Stack (axis=0):      \", nb.stack([a, b], axis=0).shape)\n",
    "print(\"Stack (axis=1):      \", nb.stack([a, b], axis=1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eddcc5c",
   "metadata": {},
   "source": [
    "## 9. Broadcasting\n",
    "\n",
    "Nabla follows NumPy broadcasting rules."
   ]
  },
  {
   "cell_type": "code",
   "id": "84f1058b",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nb.uniform((3, 1))\n",
    "y = nb.uniform((1, 4))\n",
    "z = x + y  # Broadcasts to (3, 4)\n",
    "print(f\"x: {x.shape} + y: {y.shape} = z: {z.shape}\")\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "id": "435fdf81",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicit broadcast\n",
    "v = nb.Tensor.from_dlpack(np.array([1.0, 2.0, 3.0], dtype=np.float32))\n",
    "b = nb.broadcast_to(v, (4, 3))\n",
    "print(f\"Broadcast {v.shape} → {b.shape}:\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46257124",
   "metadata": {},
   "source": [
    "## 10. Type Casting"
   ]
  },
  {
   "cell_type": "code",
   "id": "2ecd7dc1",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nb.ones((3,), dtype=nb.DType.float32)\n",
    "print(f\"Original dtype: {x.dtype}\")\n",
    "\n",
    "x_int = nb.cast(x, nb.DType.int32)\n",
    "print(f\"Cast to int32:  {x_int.dtype}\")\n",
    "\n",
    "x_f64 = nb.cast(x, nb.DType.float64)\n",
    "print(f\"Cast to float64: {x_f64.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253952af",
   "metadata": {},
   "source": [
    "## 11. Comparisons and Logical Operations"
   ]
  },
  {
   "cell_type": "code",
   "id": "974356db",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nb.Tensor.from_dlpack(np.array([1.0, 2.0, 3.0, 4.0], dtype=np.float32))\n",
    "b = nb.Tensor.from_dlpack(np.array([2.0, 2.0, 4.0, 3.0], dtype=np.float32))\n",
    "\n",
    "print(\"a:\", a)\n",
    "print(\"b:\", b)\n",
    "print(\"a == b:\", nb.equal(a, b))\n",
    "print(\"a > b: \", nb.greater(a, b))\n",
    "print(\"a < b: \", nb.less(a, b))\n",
    "print(\"a >= b:\", nb.greater_equal(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "id": "d52e23d0",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where (conditional select)\n",
    "mask = nb.greater(a, b)\n",
    "result = nb.where(mask, a, b)  # Pick a where a > b, else b\n",
    "print(\"where(a > b, a, b):\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36ff0ab",
   "metadata": {},
   "source": [
    "## 12. Softmax"
   ]
  },
  {
   "cell_type": "code",
   "id": "898ef63f",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = nb.Tensor.from_dlpack(\n",
    "    np.array([[2.0, 1.0, 0.1], [0.5, 2.0, 0.3]], dtype=np.float32)\n",
    ")\n",
    "probs = nb.softmax(logits, axis=-1)\n",
    "print(\"Logits:\\n\", logits)\n",
    "print(\"Softmax:\\n\", probs)\n",
    "print(\"Row sums:\", nb.reduce_sum(probs, axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071b7631",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this example you learned how to:\n",
    "- Create tensors from NumPy arrays, factory functions, and constants\n",
    "- Perform arithmetic, element-wise, and matrix operations\n",
    "- Reduce tensors along axes (sum, mean, max, min, argmax)\n",
    "- Manipulate shapes (reshape, transpose, squeeze, unsqueeze)\n",
    "- Use broadcasting, type casting, comparisons, and softmax\n",
    "\n",
    "All operations are **lazy** — they build a computation graph that's evaluated\n",
    "on demand. This enables powerful optimizations when combined with `@nb.compile`.\n",
    "\n",
    "**Next:** [02_autodiff](02_autodiff) — Automatic differentiation with Nabla."
   ]
  },
  {
   "cell_type": "code",
   "id": "2c41e915",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n✅ Example 01 completed!\")"
   ]
  }
 ]
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f89114",
   "metadata": {},
   "source": [
    "# Understanding Nabla - Program Transformations (Part 1)\n",
    "\n",
    "This notebook demonstrates how transformations like `vmap`, `grad` or `jit` modify a Python program in Nabla.\n",
    "\n",
    "In order to visualize how Nabla works under the hood, we need two things:\n",
    "\n",
    "- `nabla.xpr(<function>, *<args>)` - Shows intermediate representation of a traced program: inputs â†’ operations â†’ outputs  \n",
    "- `nabla.jit(<function>, show_graph=True)` - Shows compiled MAX graph (JIT only). The JIT-trafo transforms the intermediate representation into optimized machine code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abddf1a3",
   "metadata": {},
   "source": [
    "## 1. Defining and Visualizing a Python Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fb4dbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ Nabla is ready! Running on Python 3.12\n"
     ]
    }
   ],
   "source": [
    "# Installation\n",
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "try:\n",
    "    import nabla as nb\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "\n",
    "    subprocess.run(\n",
    "        [\n",
    "            sys.executable,\n",
    "            \"-m\",\n",
    "            \"pip\",\n",
    "            \"install\",\n",
    "            \"modular\",\n",
    "            \"--extra-index-url\",\n",
    "            \"https://download.pytorch.org/whl/cpu\",\n",
    "            \"--index-url\",\n",
    "            \"https://dl.modular.com/public/nightly/python/simple/\",\n",
    "        ],\n",
    "        check=True,\n",
    "    )\n",
    "    subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"nabla-ml\", \"--upgrade\"], check=True\n",
    "    )\n",
    "    import nabla as nb\n",
    "\n",
    "print(\n",
    "    f\"ðŸŽ‰ Nabla is ready! Running on Python {sys.version_info.major}.{sys.version_info.minor}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9021a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base XPR: { lambda (a:\u001b[95mf32[5]\u001b[0m) ;\n",
      "  let\n",
      "    b:\u001b[95mf32[]\u001b[0m = 2.0\n",
      "    c:\u001b[95mf32[5]\u001b[0m = mul a b\n",
      "    d:\u001b[95mf32[5]\u001b[0m = mul c a\n",
      "    e:\u001b[95mf32[1]\u001b[0m = sum[axes=[-1]] d\n",
      "    f:\u001b[95mf32[]\u001b[0m = squeeze[axes=[-1]] e\n",
      "  in f }\n",
      "\n",
      "res: 25.47862:\u001b[95mf32[]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def function(input):\n",
    "    return nb.sum(input * 2 * input, axes=0)\n",
    "\n",
    "\n",
    "input = nb.randn((5,))\n",
    "print(\"Base XPR:\", nb.xpr(function, input))\n",
    "print(\"\\nres:\", function(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f0a75b",
   "metadata": {},
   "source": [
    "## 3. Gradient Transformation\n",
    "`nb.grad()` transforms the program by adding `vjp-nodes` during backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "829dfc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient XPR: { lambda (a:\u001b[95mf32[5]\u001b[0m) ;\n",
      "  let\n",
      "    b:\u001b[95mf32[]\u001b[0m = array(1., dtype=float32)\n",
      "    c:\u001b[95mf32[1]\u001b[0m = unsqueeze[axes=[-1]] b\n",
      "    d:\u001b[95mf32[5]\u001b[0m = broadcast[shape=(5,)] c\n",
      "    e:\u001b[95mf32[5]\u001b[0m = shallow_copy a\n",
      "    f:\u001b[95mf32[]\u001b[0m = 2.0\n",
      "    g:\u001b[95mf32[5]\u001b[0m = mul e f\n",
      "    h:\u001b[95mf32[5]\u001b[0m = mul d g\n",
      "    i:\u001b[95mf32[5]\u001b[0m = mul d e\n",
      "    j:\u001b[95mf32[5]\u001b[0m = mul i f\n",
      "    k:\u001b[95mf32[5]\u001b[0m = add h j\n",
      "  in k }\n",
      "\n",
      "Gradient res: [7.0562096 1.6006289 3.914952  8.9635725 7.470232 ]:\u001b[95mf32[5]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "grad_function = nb.grad(function)\n",
    "print(\"Gradient XPR:\", nb.xpr(grad_function, input))\n",
    "print(\"\\nGradient res:\", grad_function(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d62417c",
   "metadata": {},
   "source": [
    "## 4. Vectorization Transformation\n",
    "`nb.vmap()` adds batch processing. **Blue numbers** in shapes indicate batched dimensions (vs pink for regular dims)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3632a717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized XPR: { lambda (a:\u001b[95mf32[3\u001b[95m,\u001b[95m5]\u001b[0m) ;\n",
      "  let\n",
      "    b:\u001b[95mf32[\u001b[94m3\u001b[95m]\u001b[0m = shallow_copy\n",
      "    c:\u001b[95mf32[\u001b[94m3\u001b[95m\u001b[95m,\u001b[95m1]\u001b[0m = unsqueeze[axes=[-1]] b\n",
      "    d:\u001b[95mf32[\u001b[94m3\u001b[95m\u001b[95m,\u001b[95m5]\u001b[0m = broadcast[shape=(5,)] c\n",
      "    e:\u001b[95mf32[\u001b[94m3\u001b[95m\u001b[95m,\u001b[95m5]\u001b[0m = incr_batch_dim_ctr a\n",
      "    f:\u001b[95mf32[\u001b[94m3\u001b[95m\u001b[95m,\u001b[95m5]\u001b[0m = permute_batch_dims[axes=(-1,)] e\n",
      "    g:\u001b[95mf32[\u001b[94m3\u001b[95m\u001b[95m,\u001b[95m5]\u001b[0m = shallow_copy f\n",
      "    h:\u001b[95mf32[]\u001b[0m = 2.0\n",
      "    i:\u001b[95mf32[\u001b[94m3\u001b[95m\u001b[95m,\u001b[95m5]\u001b[0m = mul g h\n",
      "    j:\u001b[95mf32[\u001b[94m3\u001b[95m\u001b[95m,\u001b[95m5]\u001b[0m = mul d i\n",
      "    k:\u001b[95mf32[\u001b[94m3\u001b[95m\u001b[95m,\u001b[95m5]\u001b[0m = mul d g\n",
      "    l:\u001b[95mf32[\u001b[94m3\u001b[95m\u001b[95m,\u001b[95m5]\u001b[0m = mul k h\n",
      "    m:\u001b[95mf32[\u001b[94m3\u001b[95m\u001b[95m,\u001b[95m5]\u001b[0m = add j l\n",
      "    n:\u001b[95mf32[\u001b[94m3\u001b[95m\u001b[95m,\u001b[95m5]\u001b[0m = permute_batch_dims[axes=(-1,)] m\n",
      "    o:\u001b[95mf32[3\u001b[95m,\u001b[95m5]\u001b[0m = decr_batch_dim_ctr n\n",
      "  in o }\n",
      "\n",
      "Vectorized res: [[ 7.0562096   1.6006289   3.914952    8.9635725   7.470232  ]\n",
      " [-3.9091115   3.8003538  -0.6054288  -0.4128754   1.6423941 ]\n",
      " [ 0.57617426  5.817094    3.0441508   0.48670006  1.775453  ]]:\u001b[95mf32[3\u001b[95m,\u001b[95m5]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "vmapped_grad_function = nb.vmap(nb.grad(function), in_axes=0)\n",
    "batched_input = nb.randn((3, 5))\n",
    "print(\"Vectorized XPR:\", nb.xpr(vmapped_grad_function, batched_input))\n",
    "print(\"\\nVectorized res:\", vmapped_grad_function(batched_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e30e8b",
   "metadata": {},
   "source": [
    "## 5. Compilation Transformation with MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9479dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mo.graph @nabla_graph(%arg0: !mo.tensor<[3, 5], f32, cpu:0>) -> !mo.tensor<[3, 5], f32, cpu:0> attributes {argument_names = [\"input0\"], inputParams = #kgen<param.decls[]>, result_names = [\"output0\"]} {\n",
      "  %0 = mo.chain.create()\n",
      "  %1 = mo.constant {value = #M.dense_array<2.000000e+00> : tensor<f32>} : !mo.tensor<[], f32, cpu:0>\n",
      "  %2 = mo.constant {value = #M.dense_array<1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00> : tensor<3x5xf32>} : !mo.tensor<[3, 5], f32, cpu:0>\n",
      "  %3 = rmo.mul(%2, %arg0) : (!mo.tensor<[3, 5], f32, cpu:0>, !mo.tensor<[3, 5], f32, cpu:0>) -> !mo.tensor<[3, 5], f32, cpu:0>\n",
      "  %4 = rmo.mul(%3, %1) : (!mo.tensor<[3, 5], f32, cpu:0>, !mo.tensor<[], f32, cpu:0>) -> !mo.tensor<[3, 5], f32, cpu:0>\n",
      "  %5 = rmo.mul(%arg0, %1) : (!mo.tensor<[3, 5], f32, cpu:0>, !mo.tensor<[], f32, cpu:0>) -> !mo.tensor<[3, 5], f32, cpu:0>\n",
      "  %6 = rmo.mul(%2, %5) : (!mo.tensor<[3, 5], f32, cpu:0>, !mo.tensor<[3, 5], f32, cpu:0>) -> !mo.tensor<[3, 5], f32, cpu:0>\n",
      "  %7 = rmo.add(%6, %4) : (!mo.tensor<[3, 5], f32, cpu:0>, !mo.tensor<[3, 5], f32, cpu:0>) -> !mo.tensor<[3, 5], f32, cpu:0>\n",
      "  mo.output %7 : !mo.tensor<[3, 5], f32, cpu:0>\n",
      "} {counter = 24 : i64}\n",
      "\n",
      "Jitted Vectorized res: [[ 7.0562096   1.6006289   3.914952    8.9635725   7.470232  ]\n",
      " [-3.9091115   3.8003538  -0.6054288  -0.4128754   1.6423941 ]\n",
      " [ 0.57617426  5.817094    3.0441508   0.48670006  1.775453  ]]:\u001b[95mf32[3\u001b[95m,\u001b[95m5]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jitted_vmapped_grad_function = nb.jit(nb.vmap(nb.grad(function)), show_graph=True)\n",
    "res = jitted_vmapped_grad_function(batched_input)\n",
    "print(\"\\nJitted Vectorized res:\", res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Nabla Development)",
   "language": "python",
   "name": "nabla-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

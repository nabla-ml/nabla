{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f89114",
   "metadata": {},
   "source": [
    "# Function Transforms Uncovered\n",
    "\n",
    "This notebook demonstrates how transformations like `vmap`, `grad` or `jit` modify a Python program under the hood.\n",
    "\n",
    "In order to visualize how Nabla works, we need two things:\n",
    "\n",
    "- `nabla.xpr(<function>, *<args>)` - Shows intermediate representation of a traced program: inputs â†’ operations â†’ outputs  \n",
    "- `nabla.jit(<function>, show_graph=True)` - Shows compiled MAX graph (JIT only). The JIT-trafo transforms the intermediate representation into optimized machine code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abddf1a3",
   "metadata": {},
   "source": [
    "## 1. Defining and Visualizing a Python Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fb4dbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ All libraries loaded successfully! Python 3.10\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "try:\n",
    "    import nabla as nb\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    packages = [\"nabla-ml\"]\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\"] + packages, check=True)\n",
    "    import nabla as nb\n",
    "\n",
    "print(\n",
    "    f\"ðŸŽ‰ All libraries loaded successfully! Python {sys.version_info.major}.{sys.version_info.minor}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9021a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base XPR: { lambda (a:\u001b[95mf32[5]:cpu(0)\u001b[0m) ;\n",
      "  let\n",
      "    b:\u001b[95mf32[1]:cpu(0)\u001b[0m = unsqueeze[axes=[-1]]\n",
      "    c:\u001b[95mf32[5]:cpu(0)\u001b[0m = mul a b\n",
      "    d:\u001b[95mf32[5]:cpu(0)\u001b[0m = mul c a\n",
      "    e:\u001b[95mf32[1]:cpu(0)\u001b[0m = sum[axes=[-1]] d\n",
      "    f:\u001b[95mf32[]:cpu(0)\u001b[0m = squeeze[axes=[-1]] e\n",
      "  in f }\n",
      "\n",
      "res: 25.47862:\u001b[95mf32[]:cpu(0)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def function(input):\n",
    "    return nb.sum(input * 2 * input, axes=0)\n",
    "\n",
    "\n",
    "input = nb.randn((5,))\n",
    "print(\"Base XPR:\", nb.xpr(function, input))\n",
    "print(\"\\nres:\", function(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f0a75b",
   "metadata": {},
   "source": [
    "## 3. Gradient Transformation\n",
    "`nb.grad()` transforms the program by adding `vjp-nodes` during backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "829dfc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient XPR: { lambda (a:\u001b[95mf32[5]:cpu(0)\u001b[0m) ;\n",
      "  let\n",
      "    b:\u001b[95mf32[]:cpu(0)\u001b[0m = 1.0\n",
      "    c:\u001b[95mf32[]:cpu(0)\u001b[0m = shallow_copy b\n",
      "    d:\u001b[95mf32[1]:cpu(0)\u001b[0m = unsqueeze[axes=[-1]] c\n",
      "    e:\u001b[95mf32[5]:cpu(0)\u001b[0m = broadcast[shape=(5,)] d\n",
      "    f:\u001b[95mf32[5]:cpu(0)\u001b[0m = shallow_copy a\n",
      "    g:\u001b[95mf32[1]:cpu(0)\u001b[0m = unsqueeze[axes=[-1]]\n",
      "    h:\u001b[95mf32[5]:cpu(0)\u001b[0m = mul f g\n",
      "    i:\u001b[95mf32[5]:cpu(0)\u001b[0m = mul e h\n",
      "    j:\u001b[95mf32[5]:cpu(0)\u001b[0m = mul e f\n",
      "    k:\u001b[95mf32[5]:cpu(0)\u001b[0m = mul j g\n",
      "    l:\u001b[95mf32[5]:cpu(0)\u001b[0m = add i k\n",
      "  in l }\n",
      "\n",
      "Gradient res: [7.0562096 1.6006289 3.914952  8.9635725 7.470232 ]:\u001b[95mf32[5]:cpu(0)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "grad_function = nb.grad(function)\n",
    "print(\"Gradient XPR:\", nb.xpr(grad_function, input))\n",
    "print(\"\\nGradient res:\", grad_function(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d62417c",
   "metadata": {},
   "source": [
    "## 4. Vectorization Transformation\n",
    "`nb.vmap()` adds batch processing. **Blue numbers** in shapes indicate batched dimensions (vs pink for regular dims)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3632a717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized XPR: { lambda (a:\u001b[95mf32[3\u001b[95m,\u001b[95m5]:cpu(0)\u001b[0m) ;\n",
      "  let\n",
      "    b:\u001b[95mf32[]:cpu(0)\u001b[0m = 1.0\n",
      "    c:\u001b[95mf32[\u001b[94m1\u001b[95m]:cpu(0)\u001b[0m = unsqueeze_batch_dims[axes=[-1]] b\n",
      "    d:\u001b[95mf32[\u001b[94m3\u001b[95m]:cpu(0)\u001b[0m = broadcast_batch_dims[shape=(3,)] c\n",
      "    e:\u001b[95mf32[\u001b[94m3\u001b[95m]:cpu(0)\u001b[0m = shallow_copy d\n",
      "    f:\u001b[95mf32[\u001b[94m3\u001b[95m\u001b[95m,\u001b[95m1]:cpu(0)\u001b[0m = unsqueeze[axes=[-1]] e\n",
      "    g:\u001b[95mf32[\u001b[94m3\u001b[95m\u001b[95m,\u001b[95m5]:cpu(0)\u001b[0m = broadcast[shape=(5,)] f\n",
      "    h:\u001b[95mf32[\u001b[94m3\u001b[95m\u001b[95m,\u001b[95m5]:cpu(0)\u001b[0m = incr_batch_dim_ctr a\n",
      "    i:\u001b[95mf32[\u001b[94m3\u001b[95m\u001b[95m,\u001b[95m5]:cpu(0)\u001b[0m = shallow_copy h\n",
      "    j:\u001b[95mf32[1]:cpu(0)\u001b[0m = unsqueeze[axes=[-1]]\n",
      "    k:\u001b[95mf32[\u001b[94m3\u001b[95m\u001b[95m,\u001b[95m5]:cpu(0)\u001b[0m = mul i j\n",
      "    l:\u001b[95mf32[\u001b[94m3\u001b[95m\u001b[95m,\u001b[95m5]:cpu(0)\u001b[0m = mul g k\n",
      "    m:\u001b[95mf32[\u001b[94m3\u001b[95m\u001b[95m,\u001b[95m5]:cpu(0)\u001b[0m = mul g i\n",
      "    n:\u001b[95mf32[\u001b[94m3\u001b[95m\u001b[95m,\u001b[95m5]:cpu(0)\u001b[0m = mul m j\n",
      "    o:\u001b[95mf32[\u001b[94m3\u001b[95m\u001b[95m,\u001b[95m5]:cpu(0)\u001b[0m = add l n\n",
      "    p:\u001b[95mf32[3\u001b[95m,\u001b[95m5]:cpu(0)\u001b[0m = decr_batch_dim_ctr o\n",
      "  in p }\n",
      "\n",
      "Vectorized res: [[ 7.0562096   1.6006289   3.914952    8.9635725   7.470232  ]\n",
      " [-3.9091115   3.8003538  -0.6054288  -0.4128754   1.6423941 ]\n",
      " [ 0.57617426  5.817094    3.0441508   0.48670006  1.775453  ]]:\u001b[95mf32[3\u001b[95m,\u001b[95m5]:cpu(0)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "vmapped_grad_function = nb.vmap(nb.grad(function), in_axes=0)\n",
    "batched_input = nb.randn((3, 5))\n",
    "print(\"Vectorized XPR:\", nb.xpr(vmapped_grad_function, batched_input))\n",
    "print(\"\\nVectorized res:\", vmapped_grad_function(batched_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e30e8b",
   "metadata": {},
   "source": [
    "## 5. Compilation Transformation with MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9479dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mo.graph @nabla_graph(%arg0: !mo.tensor<[3, 5], f32>) -> !mo.tensor<[3, 5], f32> attributes {_kernel_library_paths = [], argument_names = [\"input0\"], result_names = [\"output0\"]} {\n",
      "  %0 = mo.chain.create()\n",
      "  %1 = mo.constant {value = #M.dense_array<2.000000e+00> : tensor<1xf32>} : !mo.tensor<[1], f32>\n",
      "  %2 = mo.constant {value = #M.dense_array<1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00, 1.000000e+00> : tensor<3x5xf32>} : !mo.tensor<[3, 5], f32>\n",
      "  %3 = rmo.mul(%2, %arg0) : (!mo.tensor<[3, 5], f32>, !mo.tensor<[3, 5], f32>) -> !mo.tensor<[3, 5], f32>\n",
      "  %4 = rmo.mul(%3, %1) : (!mo.tensor<[3, 5], f32>, !mo.tensor<[1], f32>) -> !mo.tensor<[3, 5], f32>\n",
      "  %5 = rmo.mul(%arg0, %1) : (!mo.tensor<[3, 5], f32>, !mo.tensor<[1], f32>) -> !mo.tensor<[3, 5], f32>\n",
      "  %6 = rmo.mul(%2, %5) : (!mo.tensor<[3, 5], f32>, !mo.tensor<[3, 5], f32>) -> !mo.tensor<[3, 5], f32>\n",
      "  %7 = rmo.add(%6, %4) : (!mo.tensor<[3, 5], f32>, !mo.tensor<[3, 5], f32>) -> !mo.tensor<[3, 5], f32>\n",
      "  mo.output %7 : !mo.tensor<[3, 5], f32>\n",
      "} {counter = 24 : i64}\n",
      "\n",
      "Jitted Vectorized res: [[ 7.0562096   1.6006289   3.914952    8.9635725   7.470232  ]\n",
      " [-3.9091115   3.8003538  -0.6054288  -0.4128754   1.6423941 ]\n",
      " [ 0.57617426  5.817094    3.0441508   0.48670006  1.775453  ]]:\u001b[95mf32[3\u001b[95m,\u001b[95m5]:cpu(0)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jitted_vmapped_grad_function = nb.jit(nb.vmap(nb.grad(function)), show_graph=True)\n",
    "res = jitted_vmapped_grad_function(batched_input)\n",
    "print(\"\\nJitted Vectorized res:\", res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

output of the benchmark1.py file:
====================================================================
      The Ultimate Combined Benchmark Suite
====================================================================


==================== PART 1: FOUNDATIONAL BENCHMARKS ====================

========== LEVEL 1: Contrasting AD Modes ==========
[*] Testing: Reverse-Mode on Many-to-One (jacrev)
  - Correctness: OK
  - Nabla:   0.1960 ms
  - JAX:     0.1227 ms  (Nabla is 1.60x slower)
---------------------------------------------
[*] Testing: Forward-Mode on One-to-Many (jacfwd)
  - Correctness: OK
  - Nabla:   0.0979 ms
  - JAX:     0.0408 ms  (Nabla is 2.40x slower)
---------------------------------------------
[*] Testing: Higher-Order (HVP) (hvp)
  - Correctness: OK
  - Nabla:   0.1266 ms
  - JAX:     0.0852 ms  (Nabla is 1.49x slower)
---------------------------------------------

========== LEVEL 2: Deep Sequential Chain ==========
[*] Testing: Reverse-Mode (jacrev)
  - Correctness: OK
  - Nabla:   0.1415 ms
  - JAX:     0.0397 ms  (Nabla is 3.56x slower)
---------------------------------------------

========== LEVEL 3: Wide Parallel Graph ==========
[*] Testing: Reverse-Mode (jacrev)
  - Correctness: OK
  - Nabla:   0.4223 ms  (Nabla is 1.09x faster)
  - JAX:     0.4616 ms
---------------------------------------------

========== LEVEL 4: Large MLP HVP ==========
[*] Testing: Higher-Order (HVP) (hvp)
  - Correctness: OK
  - Nabla:   0.1864 ms  (Nabla is 1.83x faster)
  - JAX:     0.3413 ms
---------------------------------------------

========== LEVEL 5: Nested Derivatives (Full Hessian) ==========
[*] Testing: Full Hessian (hessian)
  - Correctness: OK
  - Nabla:   0.0978 ms
  - JAX:     0.0339 ms  (Nabla is 2.89x slower)
---------------------------------------------

========== LEVEL 6: Operation-Specific Performance ==========
[*] Testing: Element-wise Heavy (jacrev)
  - Correctness: OK
  - Nabla:   1.4653 ms
  - JAX:     1.3982 ms  (Nabla is 1.05x slower)
---------------------------------------------
[*] Testing: Matmul Heavy (jacrev)
  - Correctness: OK
  - Nabla:   0.1036 ms
  - JAX:     0.0325 ms  (Nabla is 3.19x slower)
---------------------------------------------

========== LEVEL 7: Complex Graph (ResNet Block) ==========
[*] Testing: ResNet-style Block (jacrev)
  - Correctness: OK
  - Nabla:   0.1230 ms  (Nabla is 2.10x faster)
  - JAX:     0.2585 ms
---------------------------------------------

========== LEVEL 8: Auto-Batching (vmap) ==========
[*] Testing: Vmap on MLP (vmap)
  - Correctness: OK
  - Nabla:   0.1779 ms  (Nabla is 1.97x faster)
  - JAX:     0.3507 ms
---------------------------------------------


==================== PART 2: THE LADDER OF COMPLEXITY ====================

========== LADDER STEP 1: Layer Normalization ==========
[*] Testing: Grad of LayerNorm (jacrev)
  - Correctness: OK
  - Nabla:   0.1202 ms
  - JAX:     0.0780 ms  (Nabla is 1.54x slower)
---------------------------------------------

========== LADDER STEP 1.5: Batch vs Layer Normalization ==========
[*] Testing: Grad of BatchNorm (jacrev)
  - Correctness: OK
  - Nabla:   0.0996 ms
  - JAX:     0.0285 ms  (Nabla is 3.49x slower)
---------------------------------------------

========== LADDER STEP 2: Self-Attention Head ==========
[*] Testing: Grad of Simplified Self-Attention (jacrev)
  - Correctness: OK
  - Nabla:   0.1490 ms  (Nabla is 2.64x faster)
  - JAX:     0.3939 ms
---------------------------------------------

========== LADDER STEP 2.5: Multi-Head Attention ==========
[*] Testing: Grad of Simplified Multi-Head Attention (jacrev)
  - Correctness: OK
  - Nabla:   0.1457 ms  (Nabla is 2.59x faster)
  - JAX:     0.3773 ms
---------------------------------------------

========== LADDER STEP 3: Simulated 2D Convolution ==========
[*] Testing: Grad of Conv via Matmul (jacrev)
  - Correctness: OK
  - Nabla:   0.0786 ms
  - JAX:     0.0204 ms  (Nabla is 3.86x slower)
---------------------------------------------

========== LADDER STEP 3.5: LSTM-Style Gating ==========
[*] Testing: Grad of LSTM Cell (jacrev)
  - Correctness: OK
  - Nabla:   0.1732 ms
  - JAX:     0.1003 ms  (Nabla is 1.73x slower)
---------------------------------------------

========== LADDER STEP 4: Full Transformer Block ==========
[*] Testing: Grad of Transformer Block (jacrev)
  - Correctness: OK
  - Nabla:   1.0183 ms  (Nabla is 1.65x faster)
  - JAX:     1.6812 ms
---------------------------------------------

========== LADDER STEP 5: Cross-Entropy Loss ==========
[*] Testing: Grad of Cross-Entropy (jacrev)
  - Correctness: OK
  - Nabla:   0.1607 ms
  - JAX:     0.1605 ms  (Nabla is 1.00x slower)
---------------------------------------------

========== LADDER STEP 6: Gradient Accumulation ==========
[*] Testing: Grad of Accumulation (jacrev)
  - Correctness: OK
  - Nabla:   0.2341 ms
  - JAX:     0.1673 ms  (Nabla is 1.40x slower)
---------------------------------------------

========== LADDER STEP 7: Simple 2D Attention ==========
[*] Testing: Grad of Simple Attention (jacrev)
  - Correctness: OK
  - Nabla:   7.5812 ms  (Nabla is 1.04x faster)
  - JAX:     7.9022 ms
---------------------------------------------


==================== PART 3: NESTED JACOBIAN BENCHMARKS ====================
Testing deeply nested automatic differentiation up to 3 levels
Note: Using smaller inputs due to exponential memory growth in nested operations

========== NESTED LEVEL 1: Single Jacobians ==========
[*] Testing: Jacrev of Quadratic (jacrev)
  - Correctness: OK
  - Nabla:   0.0513 ms
  - JAX:     0.0111 ms  (Nabla is 4.62x slower)
---------------------------------------------
[*] Testing: Jacfwd of Quadratic (jacfwd)
  - Correctness: OK
  - Nabla:   0.0898 ms
  - JAX:     0.0294 ms  (Nabla is 3.05x slower)
---------------------------------------------

========== NESTED LEVEL 2: Double Jacobians ==========
[*] Testing: Jacrev(Jacrev) (jacrev)
  - Correctness: OK
  - Nabla:   0.0987 ms
  - JAX:     0.0255 ms  (Nabla is 3.88x slower)
---------------------------------------------
[*] Testing: Jacfwd(Jacfwd) (jacrev)
  - Correctness: OK
  - Nabla:   0.1249 ms
  - JAX:     0.0318 ms  (Nabla is 3.92x slower)
---------------------------------------------
[*] Testing: Jacrev(Jacfwd) (jacrev)
  - Correctness: OK
  - Nabla:   0.0981 ms
  - JAX:     0.0382 ms  (Nabla is 2.56x slower)
---------------------------------------------
[*] Testing: Jacfwd(Jacrev) (jacrev)
  - Correctness: OK
  - Nabla:   0.0955 ms
  - JAX:     0.0261 ms  (Nabla is 3.66x slower)
---------------------------------------------

========== NESTED LEVEL 3: Triple Jacobians ==========
[*] Testing: Triple Jacrev (Trigonometric) (jacrev)
  - Correctness: OK
  - Nabla:   0.0497 ms
  - JAX:     0.0132 ms  (Nabla is 3.76x slower)
---------------------------------------------
[*] Testing: Triple Jacfwd (Trigonometric) (jacrev)
  - Correctness: OK
  - Nabla:   0.0956 ms
  - JAX:     0.0269 ms  (Nabla is 3.55x slower)
---------------------------------------------
[*] Testing: Triple Mixed (Rev-Fwd-Rev) (jacrev)
  - Correctness: OK
  - Nabla:   0.0881 ms
  - JAX:     0.0239 ms  (Nabla is 3.68x slower)
---------------------------------------------

========== NESTED APPLICATIONS: Real-World Cases ==========
[*] Testing: Hessian of Neural Net (jacrev)
  - Correctness: OK
  - Nabla:   0.1527 ms
  - JAX:     0.0570 ms  (Nabla is 2.68x slower)
---------------------------------------------
[*] Testing: GradÂ² of Attention (jacrev)
  - Correctness: OK
  - Nabla:   0.1588 ms
  - JAX:     0.0770 ms  (Nabla is 2.06x slower)
---------------------------------------------
[*] Testing: Triple Grad Cross-Entropy (jacrev)
  - Correctness: OK
  - Nabla:   2.8370 ms
  - JAX:     1.8309 ms  (Nabla is 1.55x slower)
---------------------------------------------




json output of the benchmark2.py file:
{
  "attention_scaling": {
    "nabla": {
      "64": {
        "compilation_time": 4537.028625025414,
        "execution_time": 1.16804099525325,
        "peak_memory": 1.234527587890625,
        "total_time": 4538.196666020667
      },
      "128": {
        "compilation_time": 4586.813208006788,
        "execution_time": 1.4547089813277125,
        "peak_memory": 0.4063711166381836,
        "total_time": 4588.267916988116
      },
      "256": {
        "compilation_time": 4617.458207998425,
        "execution_time": 2.871500008041039,
        "peak_memory": 0.3947029113769531,
        "total_time": 4620.329708006466
      },
      "512": {
        "compilation_time": 4477.7194159978535,
        "execution_time": 7.141000009141862,
        "peak_memory": 0.3947935104370117,
        "total_time": 4484.860416006995
      },
      "1024": {
        "compilation_time": 5565.442708000774,
        "execution_time": 15.196124993963167,
        "peak_memory": 0.39217090606689453,
        "total_time": 5580.638832994737
      }
    },
    "jax": {
      "64": {
        "compilation_time": 47.858749981969595,
        "execution_time": 4.49654200929217,
        "peak_memory": 0.14040756225585938,
        "total_time": 52.355291991261765
      },
      "128": {
        "compilation_time": 46.06833300204016,
        "execution_time": 7.3723339883144945,
        "peak_memory": 0.0945892333984375,
        "total_time": 53.44066699035466
      },
      "256": {
        "compilation_time": 52.63245801324956,
        "execution_time": 16.006375022698194,
        "peak_memory": 0.09207439422607422,
        "total_time": 68.63883303594775
      },
      "512": {
        "compilation_time": 38.47104200394824,
        "execution_time": 40.75537499738857,
        "peak_memory": 0.08315277099609375,
        "total_time": 79.22641700133681
      },
      "1024": {
        "compilation_time": 70.76608401257545,
        "execution_time": 66.54450000496581,
        "peak_memory": 0.10239696502685547,
        "total_time": 137.31058401754126
      }
    }
  },
  "depth_scaling": {
    "nabla": {
      "2": {
        "total_time": 2780.127875012113,
        "peak_memory": 0.4793424606323242
      },
      "4": {
        "total_time": 2649.6546249836683,
        "peak_memory": 0.4553651809692383
      },
      "8": {
        "total_time": 2212.9642500076443,
        "peak_memory": 0.5990762710571289
      },
      "16": {
        "total_time": 2322.6404580054805,
        "peak_memory": 0.8798379898071289
      },
      "32": {
        "total_time": 2430.6680409936234,
        "peak_memory": 1.4396171569824219
      }
    },
    "jax": {
      "2": {
        "total_time": 49.984792014583945,
        "peak_memory": 0.21146869659423828
      },
      "4": {
        "total_time": 44.89654197823256,
        "peak_memory": 0.11693763732910156
      },
      "8": {
        "total_time": 66.73258397495374,
        "peak_memory": 0.18628406524658203
      },
      "16": {
        "total_time": 108.62116698990576,
        "peak_memory": 0.31732940673828125
      },
      "32": {
        "total_time": 197.1163330017589,
        "peak_memory": 0.5374107360839844
      }
    }
  },
  "memory_efficiency": {
    "nabla": {
      "64": 0.38106346130371094,
      "128": 0.477813720703125,
      "256": 1.00048828125,
      "512": 4.00054931640625,
      "1024": 16.00054931640625
    },
    "jax": {
      "64": 0.15214920043945312,
      "128": 0.27087974548339844,
      "256": 1.0019054412841797,
      "512": 4.001948356628418,
      "1024": 16.022724151611328
    }
  },
  "compilation_times": {
    "nabla": {
      "simple": {
        "compilation_time": 2321.727500006091,
        "execution_time": 0.17787498654797673
      },
      "medium": {
        "compilation_time": 2598.8457080093212,
        "execution_time": 0.23341699852608144
      },
      "complex": {
        "compilation_time": 2791.6079580027144,
        "execution_time": 0.35170800401829183
      },
      "very_complex": {
        "compilation_time": 3001.899124996271,
        "execution_time": 0.3262090031057596
      }
    },
    "jax": {
      "simple": {
        "compilation_time": 32.79574998305179,
        "execution_time": 0.0475000124424696
      },
      "medium": {
        "compilation_time": 38.5273749998305,
        "execution_time": 0.276167003903538
      },
      "complex": {
        "compilation_time": 40.77354201581329,
        "execution_time": 0.33599999733269215
      },
      "very_complex": {
        "compilation_time": 39.167167007690296,
        "execution_time": 0.4270419885870069
      }
    }
  }
}